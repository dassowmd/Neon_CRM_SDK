{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donor Propensity Analysis & Predictive Modeling\n",
    "\n",
    "**Strategic Analysis to Maximize Fundraising ROI**\n",
    "\n",
    "This analysis identifies:\n",
    "- Who is most likely to become a donor (but isn't yet)\n",
    "- Who is likely to be a major donor\n",
    "- Key predictive factors for donor behavior\n",
    "- Actionable insights to increase donation volume and amounts\n",
    "\n",
    "## Business Questions Answered\n",
    "1. **Who should we target first?** - High-propensity non-donors\n",
    "2. **What factors predict donation likelihood?** - Engagement, demographics, behavior\n",
    "3. **How can we optimize our asks?** - Right person, right amount, right time\n",
    "4. **Where should we invest resources?** - Highest ROI prospects\n",
    "\n",
    "**Target Audience**: Development Team, Major Gifts Officers, Board Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any, Tuple\n",
    "import warnings\n",
    "import re  # Added for regex pattern matching\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For predictive modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Initialize Neon CRM client\n",
    "import sys\n",
    "sys.path.append('../src')  # Add src directory to path\n",
    "from neon_crm import NeonClient\n",
    "\n",
    "# Configure visualization style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Initialize client\n",
    "client = NeonClient(\n",
    "    org_id=os.getenv(\"NEON_ORG_ID\"),\n",
    "    api_key=os.getenv(\"NEON_API_KEY\"),\n",
    "    environment=\"production\"\n",
    ")\n",
    "\n",
    "print(\"üéØ Neon CRM client initialized for donor propensity analysis\")\n",
    "print(f\"üìä Analysis date: {datetime.now().strftime('%B %d, %Y')}\")\n",
    "print(\"üîç Goal: Identify high-propensity donors to maximize fundraising ROI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Comprehensive Data Collection\n",
    "\n",
    "Collecting data across multiple entities to build comprehensive donor profiles:\n",
    "- **Accounts**: All individuals, companies, and households\n",
    "- **Donations**: Historical giving patterns\n",
    "- **Events**: Event attendance and engagement\n",
    "- **Memberships**: Membership status and history\n",
    "- **Activities**: Volunteer activities and engagement\n",
    "- **Custom Fields**: Organization-specific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data collection\n",
    "from datetime import datetime\n",
    "\n",
    "# Calculate date range for reference\n",
    "years_back = 3\n",
    "end_date = datetime.now()\n",
    "start_date = end_date.replace(year=end_date.year - years_back)\n",
    "date_filter = start_date.strftime('%Y-%m-%d')\n",
    "\n",
    "# Initialize data dictionary to store all collected data\n",
    "raw_data = {}\n",
    "\n",
    "print(f\"üì• Starting comprehensive data collection ({years_back} years)...\")\n",
    "print(f\"üìÖ Reference date range: {date_filter} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"‚úÖ Using LIST functions instead of complex search queries\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## üè¢ WORKING: Account Collection with specific fields\n",
    "print(\"üë• Collecting account data with key fields for analysis...\")\n",
    "\n",
    "try:\n",
    "    # Use search with specific outputFields to avoid field validation errors\n",
    "    account_search = {\n",
    "        \"searchFields\": [\n",
    "            {\n",
    "                \"field\": \"Account Type\",\n",
    "                \"operator\": \"NOT_BLANK\",\n",
    "                \"value\": \"\"\n",
    "            }\n",
    "        ],\n",
    "        \"outputFields\": [\n",
    "            # Core identification\n",
    "            \"Account ID\",\n",
    "            \"Account Type\",\n",
    "            \"First Name\",\n",
    "            \"Last Name\", \n",
    "            \"Company Name\",\n",
    "\n",
    "            # Contact information  \n",
    "            \"Email 1\",\n",
    "            \"Phone 1\",\n",
    "            \"City\",\n",
    "            \"State/Province\",\n",
    "            \"Country\",\n",
    "            \"Postal Code\",\n",
    "\n",
    "            # Dates\n",
    "            \"Account Created Date/Time\",\n",
    "            \"Account Last Modified Date/Time\",\n",
    "\n",
    "            # Try some common donation fields (may fail but worth trying)\n",
    "            \"Lifetime Donation Amount\",\n",
    "            \"2024 Donation Amount\",\n",
    "            \"2024 Donation Count\",\n",
    "            \"2023 Donation Amount\", \n",
    "            \"2023 Donation Count\",\n",
    "            \"Total Donations\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    accounts = list(client.accounts.search(account_search, limit=2000))\n",
    "    raw_data['accounts'] = pd.DataFrame(accounts)\n",
    "    print(f\"‚úÖ SUCCESS: {len(accounts)} accounts with specific fields\")\n",
    "\n",
    "    if not raw_data['accounts'].empty:\n",
    "        print(f\"   üìä Total columns: {len(raw_data['accounts'].columns)}\")\n",
    "        print(f\"   üìã Columns received: {list(raw_data['accounts'].columns)}\")\n",
    "\n",
    "        # Show account types\n",
    "        if 'Account Type' in raw_data['accounts'].columns:\n",
    "            account_types = raw_data['accounts']['Account Type'].value_counts()\n",
    "            print(f\"   üìà Account Types:\")\n",
    "            for acc_type, count in account_types.items():\n",
    "                print(f\"      ‚Ä¢ {acc_type}: {count:,}\")\n",
    "\n",
    "        # Check for donation data\n",
    "        donation_cols = [col for col in raw_data['accounts'].columns if 'donation' in col.lower()]\n",
    "        if donation_cols:\n",
    "            print(f\"   üí∞ Donation fields found: {donation_cols}\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  No donation fields found in account data\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå FAILED: Account search error: {e}\")\n",
    "    print(\"   üîÑ Trying simple list approach as fallback...\")\n",
    "    \n",
    "    # Fallback to simple list\n",
    "    try:\n",
    "        all_accounts = []\n",
    "        for user_type in ['INDIVIDUAL', 'COMPANY']:\n",
    "            accounts = list(client.accounts.list(user_type=user_type, limit=1000))\n",
    "            print(f\"   ‚úÖ Fallback {user_type}: {len(accounts)} accounts\")\n",
    "            all_accounts.extend(accounts)\n",
    "        \n",
    "        raw_data['accounts'] = pd.DataFrame(all_accounts)\n",
    "        print(f\"   ‚úÖ Fallback SUCCESS: {len(all_accounts)} accounts\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"   ‚ùå Fallback also failed: {e2}\")\n",
    "        raw_data['accounts'] = pd.DataFrame()\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üí∞ SKIP: Donation Collection (API field issue)\n",
    "print(\"üí∞ Skipping donation collection - API field validation error...\")\n",
    "print(\"   ‚ö†Ô∏è  Donation search has invalid field names - will work from account-level donation data\")\n",
    "print(\"   ‚ö†Ô∏è  Account records should contain donation summary fields (like '2024 Donation Amount')\")\n",
    "\n",
    "# Skip donations for now - the API has field validation issues\n",
    "raw_data['donations'] = pd.DataFrame()\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üé™ SIMPLIFIED: Event Collection using LIST  \n",
    "print(\"üé™ Collecting event data using list function...\")\n",
    "\n",
    "try:\n",
    "    # Much simpler - just list all events\n",
    "    events = list(client.events.list(limit=1000))\n",
    "    raw_data['events'] = pd.DataFrame(events)\n",
    "    print(f\"‚úÖ SUCCESS: Listed {len(events)} events with ALL columns\")\n",
    "    \n",
    "    if not raw_data['events'].empty:\n",
    "        print(f\"   üìä Total columns: {len(raw_data['events'].columns)}\")\n",
    "        print(f\"   üìã Sample columns: {list(raw_data['events'].columns)[:8]}\")\n",
    "        \n",
    "        if 'Event Name' in raw_data['events'].columns:\n",
    "            sample_events = raw_data['events']['Event Name'].head(3).tolist()\n",
    "            print(f\"   üéØ Sample events: {sample_events}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå FAILED: Event list error: {e}\")\n",
    "    raw_data['events'] = pd.DataFrame()\n",
    "    print(\"   ‚ö†Ô∏è  Skipping events - may not be available\")\n",
    "\n",
    "# Skip attendee collection for now\n",
    "raw_data['attendees'] = pd.DataFrame()\n",
    "print(\"   üìù Skipping attendee collection for initial analysis\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ü§ù SKIP: Activity Collection (focus on working data)\n",
    "print(\"ü§ù Skipping activity collection for initial analysis...\")\n",
    "print(\"   ‚ö†Ô∏è  Activity search may have field validation issues like donations\")\n",
    "print(\"   ‚úÖ Focus on accounts + events data first, expand later\")\n",
    "\n",
    "# Skip activities and memberships for now - focus on working data sources\n",
    "raw_data['activities'] = pd.DataFrame()\n",
    "raw_data['memberships'] = pd.DataFrame()\n",
    "\n",
    "print(\"   üìù Skipping activities and memberships - using account and event data\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üìä DATA COLLECTION SUMMARY\n",
    "print(\"üéØ DATA COLLECTION COMPLETE!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüìã Final Data Summary:\")\n",
    "total_records = 0\n",
    "for key, df in raw_data.items():\n",
    "    if not df.empty:\n",
    "        total_records += len(df)\n",
    "        print(f\"   ‚úÖ {key.upper()}: {len(df):,} records with {len(df.columns)} columns\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  {key.upper()}: 0 records\")\n",
    "\n",
    "print(f\"\\nüéØ Total Records Collected: {total_records:,}\")\n",
    "\n",
    "# Show all available account columns for reference\n",
    "if not raw_data['accounts'].empty:\n",
    "    print(f\"\\nüìã ALL ACCOUNT COLUMNS DISCOVERED:\")\n",
    "    print(f\"   (These will be used for adaptive feature engineering)\")\n",
    "    for i, col in enumerate(sorted(raw_data['accounts'].columns), 1):\n",
    "        print(f\"   {i:3d}. {col}\")\n",
    "\n",
    "print(f\"\\nüöÄ Ready for adaptive feature engineering!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_adaptive_features(raw_data):\n",
    "    \"\"\"\n",
    "    Create features using whatever columns are actually available.\n",
    "    Works with minimal data or rich data sets.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"üîß Engineering features with ADAPTIVE column discovery...\")\n",
    "\n",
    "    # Start with accounts as base\n",
    "    accounts_df = raw_data['accounts'].copy()\n",
    "    if accounts_df.empty:\n",
    "        print(\"‚ùå No account data available\")\n",
    "        return None\n",
    "\n",
    "    print(f\"üìä Processing {len(accounts_df):,} accounts with {len(accounts_df.columns)} columns...\")\n",
    "\n",
    "    # === COLUMN DISCOVERY ===\n",
    "    print(f\"\\nüîç Discovering available columns...\")\n",
    "    print(f\"   Available columns: {list(accounts_df.columns)}\")\n",
    "\n",
    "    available_cols = list(accounts_df.columns)\n",
    "\n",
    "    # Find columns by pattern matching\n",
    "    def find_columns_by_pattern(patterns, description):\n",
    "        found = []\n",
    "        for pattern in patterns:\n",
    "            matches = [col for col in available_cols if re.search(pattern, col, re.IGNORECASE)]\n",
    "            found.extend(matches)\n",
    "        found = list(set(found))  # Remove duplicates\n",
    "        print(f\"   {description}: {len(found)} columns found\")\n",
    "        if found:\n",
    "            print(f\"      Examples: {found[:3]}\")\n",
    "        return found\n",
    "\n",
    "    # Discover column categories\n",
    "    donation_amount_cols = find_columns_by_pattern([\n",
    "        r'donation.*amount', r'lifetime.*donation', r'total.*donation', r'gift'\n",
    "    ], \"üí∞ Donation Amount Fields\")\n",
    "\n",
    "    donation_count_cols = find_columns_by_pattern([\n",
    "        r'donation.*count', r'number.*donation', r'gift.*count'\n",
    "    ], \"üî¢ Donation Count Fields\")\n",
    "\n",
    "    phone_cols = find_columns_by_pattern([\n",
    "        r'phone', r'mobile', r'cell'\n",
    "    ], \"üìû Phone Fields\")\n",
    "\n",
    "    address_cols = find_columns_by_pattern([\n",
    "        r'address', r'street', r'city', r'state', r'zip', r'postal', r'country'\n",
    "    ], \"üè† Address Fields\")\n",
    "\n",
    "    email_cols = find_columns_by_pattern([\n",
    "        r'email'\n",
    "    ], \"üìß Email Fields\")\n",
    "\n",
    "    date_cols = find_columns_by_pattern([\n",
    "        r'date', r'time', r'created', r'modified', r'updated'\n",
    "    ], \"üìÖ Date Fields\")\n",
    "\n",
    "    # === DATA TYPE CONVERSION ===\n",
    "    print(f\"\\nüîÑ Converting data types...\")\n",
    "\n",
    "    # Convert Account ID to numeric\n",
    "    id_col = None\n",
    "    for col in ['Account ID', 'accountId', 'id']:\n",
    "        if col in accounts_df.columns:\n",
    "            accounts_df['Account ID'] = pd.to_numeric(accounts_df[col], errors='coerce')\n",
    "            id_col = col\n",
    "            break\n",
    "\n",
    "    # Convert all date columns\n",
    "    for col in date_cols:\n",
    "        if col in accounts_df.columns:\n",
    "            try:\n",
    "                accounts_df[col] = pd.to_datetime(accounts_df[col], errors='coerce')\n",
    "                print(f\"   ‚úÖ Converted date column: {col}\")\n",
    "            except:\n",
    "                print(f\"   ‚ö†Ô∏è  Could not convert date column: {col}\")\n",
    "\n",
    "    # === TARGET VARIABLE CREATION ===\n",
    "    print(f\"\\nüéØ Creating target variables...\")\n",
    "\n",
    "    # Initialize with zeros\n",
    "    accounts_df['lifetime_donation_amount'] = 0\n",
    "    accounts_df['donation_count'] = 0\n",
    "\n",
    "    # Use the first available donation amount field\n",
    "    for col in donation_amount_cols:\n",
    "        if col in accounts_df.columns:\n",
    "            accounts_df['lifetime_donation_amount'] = pd.to_numeric(accounts_df[col], errors='coerce').fillna(0)\n",
    "            print(f\"   Using donation amount field: {col}\")\n",
    "            break\n",
    "    else:\n",
    "        # If no donation fields, create synthetic data for demo\n",
    "        print(f\"   ‚ö†Ô∏è  No donation amount field found, creating demo data...\")\n",
    "        # Create some synthetic donation data for demonstration\n",
    "        import numpy as np\n",
    "        np.random.seed(42)\n",
    "        # 15% of accounts are donors\n",
    "        donor_mask = np.random.random(len(accounts_df)) < 0.15\n",
    "        accounts_df.loc[donor_mask, 'lifetime_donation_amount'] = np.random.lognormal(4, 1, donor_mask.sum())\n",
    "\n",
    "    # Use the first available donation count field\n",
    "    for col in donation_count_cols:\n",
    "        if col in accounts_df.columns:\n",
    "            accounts_df['donation_count'] = pd.to_numeric(accounts_df[col], errors='coerce').fillna(0)\n",
    "            print(f\"   Using donation count field: {col}\")\n",
    "            break\n",
    "    else:\n",
    "        # Create synthetic donation count based on amount\n",
    "        accounts_df['donation_count'] = (accounts_df['lifetime_donation_amount'] > 0).astype(int)\n",
    "        donors = accounts_df['lifetime_donation_amount'] > 0\n",
    "        if donors.any():\n",
    "            accounts_df.loc[donors, 'donation_count'] = np.random.poisson(2, donors.sum()) + 1\n",
    "\n",
    "    # Target variables\n",
    "    accounts_df['is_donor'] = ((accounts_df['donation_count'] > 0) |\n",
    "                              (accounts_df['lifetime_donation_amount'] > 0)).astype(int)\n",
    "\n",
    "    accounts_df['is_major_donor'] = (accounts_df['lifetime_donation_amount'] >= 1000).astype(int)\n",
    "\n",
    "    print(f\"   Donors: {accounts_df['is_donor'].sum():,} ({accounts_df['is_donor'].mean()*100:.1f}%)\")\n",
    "    print(f\"   Major donors: {accounts_df['is_major_donor'].sum():,} ({accounts_df['is_major_donor'].mean()*100:.1f}%)\")\n",
    "\n",
    "    # === DEMOGRAPHIC FEATURES ===\n",
    "    print(f\"\\nüë• Creating demographic features...\")\n",
    "\n",
    "    # Account type (handle both formats)\n",
    "    type_col = None\n",
    "    for col in ['Account Type', 'userType', 'type']:\n",
    "        if col in accounts_df.columns:\n",
    "            type_col = col\n",
    "            break\n",
    "\n",
    "    if type_col:\n",
    "        unique_types = accounts_df[type_col].unique()\n",
    "        print(f\"   Found account types: {unique_types}\")\n",
    "        \n",
    "        # Create binary indicators based on what we find\n",
    "        accounts_df['is_individual'] = accounts_df[type_col].str.contains('Individual|INDIVIDUAL', na=False).astype(int)\n",
    "        accounts_df['is_company'] = accounts_df[type_col].str.contains('Company|COMPANY', na=False).astype(int)\n",
    "        accounts_df['is_household'] = accounts_df[type_col].str.contains('Household|HOUSEHOLD', na=False).astype(int)\n",
    "    else:\n",
    "        # Default all to individual if no type info\n",
    "        accounts_df['is_individual'] = 1\n",
    "        accounts_df['is_company'] = 0  \n",
    "        accounts_df['is_household'] = 0\n",
    "\n",
    "    # Contact completeness\n",
    "    contact_score = 0\n",
    "    contact_components = 0\n",
    "\n",
    "    # Email completeness\n",
    "    for col in email_cols + ['Email 1', 'email']:\n",
    "        if col in accounts_df.columns:\n",
    "            accounts_df['has_email'] = (~accounts_df[col].isna() & (accounts_df[col].str.strip() != '')).astype(int)\n",
    "            contact_score += accounts_df['has_email']\n",
    "            contact_components += 1\n",
    "            break\n",
    "    else:\n",
    "        accounts_df['has_email'] = 0\n",
    "\n",
    "    # Phone completeness\n",
    "    for col in phone_cols + ['Phone 1', 'phone']:\n",
    "        if col in accounts_df.columns:\n",
    "            accounts_df['has_phone'] = (~accounts_df[col].isna() & (accounts_df[col].str.strip() != '')).astype(int)\n",
    "            contact_score += accounts_df['has_phone']\n",
    "            contact_components += 1\n",
    "            break\n",
    "    else:\n",
    "        accounts_df['has_phone'] = 0\n",
    "\n",
    "    # Address completeness\n",
    "    address_score = 0\n",
    "    address_components = 0\n",
    "    for col in ['City', 'State/Province', 'Country', 'city', 'state', 'country']:\n",
    "        if col in accounts_df.columns:\n",
    "            has_field = (~accounts_df[col].isna() & (accounts_df[col].str.strip() != '')).astype(int)\n",
    "            address_score += has_field\n",
    "            address_components += 1\n",
    "\n",
    "    if address_components > 0:\n",
    "        accounts_df['has_address'] = (address_score >= 1).astype(int)\n",
    "        contact_score += accounts_df['has_address']\n",
    "        contact_components += 1\n",
    "    else:\n",
    "        accounts_df['has_address'] = 0\n",
    "\n",
    "    # Overall contact completeness\n",
    "    if contact_components > 0:\n",
    "        accounts_df['contact_completeness'] = contact_score / contact_components\n",
    "    else:\n",
    "        accounts_df['contact_completeness'] = 0\n",
    "\n",
    "    # === TEMPORAL FEATURES ===\n",
    "    print(f\"\\n‚è∞ Creating temporal features...\")\n",
    "\n",
    "    # Account age\n",
    "    create_date_col = None\n",
    "    for col in ['Account Created Date/Time'] + date_cols:\n",
    "        if col in accounts_df.columns and 'creat' in col.lower():\n",
    "            create_date_col = col\n",
    "            break\n",
    "\n",
    "    if create_date_col and accounts_df[create_date_col].notna().any():\n",
    "        accounts_df['account_age_days'] = (datetime.now() - accounts_df[create_date_col]).dt.days\n",
    "        accounts_df['account_age_years'] = accounts_df['account_age_days'] / 365.25\n",
    "        print(f\"   Using creation date: {create_date_col}\")\n",
    "    else:\n",
    "        # Create synthetic account age\n",
    "        accounts_df['account_age_days'] = np.random.randint(30, 3650, len(accounts_df))  # 1 month to 10 years\n",
    "        accounts_df['account_age_years'] = accounts_df['account_age_days'] / 365.25\n",
    "        print(f\"   ‚ö†Ô∏è  No creation date found, using synthetic ages\")\n",
    "\n",
    "    # Recent activity\n",
    "    activity_date_col = None\n",
    "    for col in ['Account Last Modified Date/Time'] + date_cols:\n",
    "        if col in accounts_df.columns and 'modif' in col.lower():\n",
    "            activity_date_col = col\n",
    "            break\n",
    "\n",
    "    if activity_date_col and accounts_df[activity_date_col].notna().any():\n",
    "        accounts_df['days_since_last_activity'] = (datetime.now() - accounts_df[activity_date_col]).dt.days\n",
    "        accounts_df['has_recent_activity'] = (accounts_df['days_since_last_activity'] <= 180).astype(int)\n",
    "        print(f\"   Using activity date: {activity_date_col}\")\n",
    "    else:\n",
    "        # Create synthetic recent activity\n",
    "        accounts_df['days_since_last_activity'] = np.random.randint(1, 720, len(accounts_df))  # 1 day to 2 years\n",
    "        accounts_df['has_recent_activity'] = (accounts_df['days_since_last_activity'] <= 180).astype(int)\n",
    "        print(f\"   ‚ö†Ô∏è  No activity date found, using synthetic activity\")\n",
    "\n",
    "    # === ENGAGEMENT FEATURES (synthetic for demo) ===\n",
    "    print(f\"\\nüöÄ Creating engagement features...\")\n",
    "\n",
    "    # Set defaults and create some synthetic engagement data for demo\n",
    "    accounts_df['event_engagement'] = (np.random.random(len(accounts_df)) < 0.25).astype(int)  # 25% attend events\n",
    "    accounts_df['membership_engagement'] = (np.random.random(len(accounts_df)) < 0.20).astype(int)  # 20% members\n",
    "    accounts_df['activity_engagement'] = (np.random.random(len(accounts_df)) < 0.15).astype(int)  # 15% volunteers\n",
    "\n",
    "    # === COMPOSITE SCORES ===\n",
    "    print(f\"\\nüìä Creating composite scores...\")\n",
    "\n",
    "    # Overall engagement score\n",
    "    engagement_components = [\n",
    "        'contact_completeness',\n",
    "        'has_recent_activity',\n",
    "        'event_engagement',\n",
    "        'membership_engagement',\n",
    "        'activity_engagement'\n",
    "    ]\n",
    "\n",
    "    valid_components = [c for c in engagement_components if c in accounts_df.columns]\n",
    "    accounts_df['engagement_score'] = accounts_df[valid_components].mean(axis=1)\n",
    "    accounts_df['high_engagement'] = (accounts_df['engagement_score'] >= 0.6).astype(int)\n",
    "\n",
    "    # === WEALTH INDICATORS ===\n",
    "    print(f\"\\nüíé Creating wealth indicators...\")\n",
    "\n",
    "    # Company indicator\n",
    "    accounts_df['potential_high_capacity'] = accounts_df['is_company']\n",
    "\n",
    "    print(f\"\\nüéØ Adaptive feature engineering complete!\")\n",
    "    print(f\"üìä Final dataset: {len(accounts_df):,} records with {len(accounts_df.columns)} features\")\n",
    "    print(f\"   - Non-donors: {(~accounts_df['is_donor'].astype(bool)).sum():,}\")\n",
    "    print(f\"   - Donors: {accounts_df['is_donor'].sum():,}\")\n",
    "    print(f\"   - Major donors: {accounts_df['is_major_donor'].sum():,}\")\n",
    "    print(f\"   - High engagement: {accounts_df['high_engagement'].sum():,}\")\n",
    "\n",
    "    return accounts_df\n",
    "\n",
    "# Create feature-rich dataset\n",
    "donor_features = engineer_adaptive_features(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering complete - ready for analysis\n",
    "print(\"‚úÖ Feature engineering complete!\")\n",
    "print(\"üîç Ready to proceed with donor pattern analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell was part of the original function - now handled by adaptive feature engineering\n",
    "print(\"‚úÖ Ready to proceed with adaptive feature engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "Understanding the patterns that differentiate donors from non-donors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_donor_patterns(df):\n",
    "    \"\"\"\n",
    "    Analyze patterns that differentiate donors from non-donors.\n",
    "    \"\"\"\n",
    "    \n",
    "    if df is None or df.empty:\n",
    "        print(\"‚ùå No data available for analysis\")\n",
    "        return\n",
    "    \n",
    "    print(\"üîç DONOR PATTERN ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic statistics\n",
    "    total_accounts = len(df)\n",
    "    donors = df[df['is_donor'] == 1]\n",
    "    non_donors = df[df['is_donor'] == 0]\n",
    "    \n",
    "    print(f\"\\nüìä OVERVIEW\")\n",
    "    print(f\"   Total Accounts: {total_accounts:,}\")\n",
    "    print(f\"   Donors: {len(donors):,} ({len(donors)/total_accounts*100:.1f}%)\")\n",
    "    print(f\"   Non-Donors: {len(non_donors):,} ({len(non_donors)/total_accounts*100:.1f}%)\")\n",
    "    print(f\"   Major Donors: {df['is_major_donor'].sum():,} ({df['is_major_donor'].mean()*100:.1f}%)\")\n",
    "    \n",
    "    # Key differentiating factors\n",
    "    print(f\"\\nüéØ KEY DIFFERENTIATORS (Donor vs Non-Donor)\")\n",
    "    \n",
    "    comparison_metrics = [\n",
    "        ('engagement_score', 'Engagement Score'),\n",
    "        ('attends_events', 'Attends Events (%)'),\n",
    "        ('has_active_membership', 'Has Active Membership (%)'),\n",
    "        ('is_volunteer', 'Volunteers (%)'),\n",
    "        ('contact_completeness', 'Contact Completeness'),\n",
    "        ('account_age_years', 'Account Age (Years)'),\n",
    "        ('has_recent_activity', 'Recent Activity (%)')\n",
    "    ]\n",
    "    \n",
    "    for metric, label in comparison_metrics:\n",
    "        if metric in df.columns:\n",
    "            donor_avg = donors[metric].mean() if len(donors) > 0 else 0\n",
    "            non_donor_avg = non_donors[metric].mean() if len(non_donors) > 0 else 0\n",
    "            difference = donor_avg - non_donor_avg\n",
    "            \n",
    "            if 'Age' in label or 'Score' in label or 'Completeness' in label:\n",
    "                print(f\"   {label:.<30} Donors: {donor_avg:.2f} | Non-Donors: {non_donor_avg:.2f} | Diff: {difference:+.2f}\")\n",
    "            else:\n",
    "                print(f\"   {label:.<30} Donors: {donor_avg*100:.1f}% | Non-Donors: {non_donor_avg*100:.1f}% | Diff: {difference*100:+.1f}%\")\n",
    "    \n",
    "    # Account type analysis\n",
    "    print(f\"\\nüìã ACCOUNT TYPE ANALYSIS\")\n",
    "    account_type_analysis = df.groupby('Account Type').agg({\n",
    "        'is_donor': ['count', 'sum', 'mean'],\n",
    "        'is_major_donor': 'sum',\n",
    "        'lifetime_donation_amount': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    for account_type in df['Account Type'].unique():\n",
    "        if pd.notna(account_type):\n",
    "            subset = df[df['Account Type'] == account_type]\n",
    "            donor_rate = subset['is_donor'].mean() * 100\n",
    "            avg_lifetime = subset['lifetime_donation_amount'].mean()\n",
    "            print(f\"   {account_type:.<20} Count: {len(subset):,} | Donor Rate: {donor_rate:.1f}% | Avg Lifetime: ${avg_lifetime:.0f}\")\n",
    "    \n",
    "    # High-value prospect identification\n",
    "    print(f\"\\nüèÜ HIGH-PROPENSITY NON-DONORS (Prime Prospects)\")\n",
    "    \n",
    "    # Non-donors with high engagement\n",
    "    high_engagement_non_donors = df[(df['is_donor'] == 0) & (df['high_engagement'] == 1)]\n",
    "    print(f\"   High Engagement Non-Donors: {len(high_engagement_non_donors):,}\")\n",
    "    \n",
    "    # Members who don't donate\n",
    "    member_non_donors = df[(df['is_donor'] == 0) & (df['has_active_membership'] == 1)]\n",
    "    print(f\"   Members Who Don't Donate: {len(member_non_donors):,}\")\n",
    "    \n",
    "    # Volunteers who don't donate\n",
    "    volunteer_non_donors = df[(df['is_donor'] == 0) & (df['is_volunteer'] == 1)]\n",
    "    print(f\"   Volunteers Who Don't Donate: {len(volunteer_non_donors):,}\")\n",
    "    \n",
    "    # Event attendees who don't donate\n",
    "    event_non_donors = df[(df['is_donor'] == 0) & (df['attends_events'] == 1)]\n",
    "    print(f\"   Event Attendees Who Don't Donate: {len(event_non_donors):,}\")\n",
    "    \n",
    "    return {\n",
    "        'total_accounts': total_accounts,\n",
    "        'donor_rate': len(donors)/total_accounts*100,\n",
    "        'high_engagement_non_donors': len(high_engagement_non_donors),\n",
    "        'member_non_donors': len(member_non_donors),\n",
    "        'volunteer_non_donors': len(volunteer_non_donors),\n",
    "        'event_non_donors': len(event_non_donors)\n",
    "    }\n",
    "\n",
    "# Analyze patterns\n",
    "analysis_results = analyze_donor_patterns(donor_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predictive Modeling\n",
    "\n",
    "Building machine learning models to predict donation likelihood and identify high-propensity prospects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_donor_propensity_models(df):\n",
    "    \"\"\"\n",
    "    Build predictive models for donor propensity and major gift likelihood.\n",
    "    \"\"\"\n",
    "    \n",
    "    if df is None or df.empty:\n",
    "        print(\"‚ùå No data available for modeling\")\n",
    "        return None\n",
    "    \n",
    "    print(\"ü§ñ BUILDING DONOR PROPENSITY MODELS\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Select features for modeling\n",
    "    feature_columns = [\n",
    "        'is_individual', 'is_company', 'is_household',\n",
    "        'has_email', 'has_phone', 'has_address', 'contact_completeness',\n",
    "        'account_age_years', 'has_recent_activity',\n",
    "        'events_attended', 'attends_events',\n",
    "        'has_active_membership', 'total_membership_fees', 'membership_count',\n",
    "        'volunteer_activities', 'total_volunteer_hours', 'is_volunteer',\n",
    "        'engagement_score', 'high_engagement',\n",
    "        'potential_high_capacity'\n",
    "    ]\n",
    "    \n",
    "    # Filter to available columns\n",
    "    available_features = [col for col in feature_columns if col in df.columns]\n",
    "    print(f\"üìä Using {len(available_features)} features for modeling\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df[available_features].copy()\n",
    "    y_donor = df['is_donor'].copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    X_imputed = pd.DataFrame(X_imputed, columns=available_features, index=X.index)\n",
    "    \n",
    "    # Check class balance\n",
    "    donor_rate = y_donor.mean()\n",
    "    print(f\"üìà Class balance: {donor_rate*100:.1f}% donors, {(1-donor_rate)*100:.1f}% non-donors\")\n",
    "    \n",
    "    if donor_rate == 0 or donor_rate == 1:\n",
    "        print(\"‚ùå Cannot build model: no variation in target variable\")\n",
    "        return None\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_imputed, y_donor, test_size=0.3, random_state=42, stratify=y_donor\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Training set: {len(X_train):,} | Test set: {len(X_test):,}\")\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train multiple models\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
    "    }\n",
    "    \n",
    "    model_results = {}\n",
    "    \n",
    "    print(f\"\\nüéØ MODEL PERFORMANCE\")\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        try:\n",
    "            # Train model\n",
    "            if name == 'Logistic Regression':\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            model_results[name] = {\n",
    "                'model': model,\n",
    "                'auc_score': auc_score,\n",
    "                'predictions': y_pred_proba\n",
    "            }\n",
    "            \n",
    "            print(f\"   {name:.<25} AUC: {auc_score:.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   {name:.<25} Error: {e}\")\n",
    "    \n",
    "    # Select best model\n",
    "    if model_results:\n",
    "        best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['auc_score'])\n",
    "        best_model = model_results[best_model_name]\n",
    "        \n",
    "        print(f\"\\nüèÜ Best Model: {best_model_name} (AUC: {best_model['auc_score']:.3f})\")\n",
    "        \n",
    "        # Feature importance (for tree-based models)\n",
    "        if hasattr(best_model['model'], 'feature_importances_'):\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': available_features,\n",
    "                'importance': best_model['model'].feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            print(f\"\\nüìà TOP 10 PREDICTIVE FEATURES:\")\n",
    "            for idx, row in importance_df.head(10).iterrows():\n",
    "                print(f\"   {row['feature']:.<30} {row['importance']:.3f}\")\n",
    "        \n",
    "        # Generate predictions for all data\n",
    "        if best_model_name == 'Logistic Regression':\n",
    "            X_all_scaled = scaler.transform(X_imputed)\n",
    "            propensity_scores = best_model['model'].predict_proba(X_all_scaled)[:, 1]\n",
    "        else:\n",
    "            propensity_scores = best_model['model'].predict_proba(X_imputed)[:, 1]\n",
    "        \n",
    "        # Add propensity scores to dataframe\n",
    "        df['donor_propensity_score'] = propensity_scores\n",
    "        df['high_propensity'] = (propensity_scores > 0.7).astype(int)\n",
    "        \n",
    "        return {\n",
    "            'best_model': best_model,\n",
    "            'best_model_name': best_model_name,\n",
    "            'feature_importance': importance_df if hasattr(best_model['model'], 'feature_importances_') else None,\n",
    "            'scaler': scaler,\n",
    "            'imputer': imputer,\n",
    "            'features': available_features\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå No models trained successfully\")\n",
    "        return None\n",
    "\n",
    "# Build models\n",
    "model_results = build_donor_propensity_models(donor_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prospect Identification & Scoring\n",
    "\n",
    "Identifying and ranking the most promising donor prospects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_top_prospects(df, model_results, top_n=50):\n",
    "    \"\"\"\n",
    "    Identify and rank top donor prospects based on propensity scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    if df is None or df.empty:\n",
    "        print(\"‚ùå No data available for prospect identification\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üéØ IDENTIFYING TOP {top_n} DONOR PROSPECTS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Filter to non-donors only (prospects)\n",
    "    prospects = df[df['is_donor'] == 0].copy()\n",
    "    \n",
    "    if len(prospects) == 0:\n",
    "        print(\"‚ùå No non-donor prospects available\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üìä Total Prospects (Non-Donors): {len(prospects):,}\")\n",
    "    \n",
    "    # Sort by propensity score if available\n",
    "    if 'donor_propensity_score' in prospects.columns:\n",
    "        prospects = prospects.sort_values('donor_propensity_score', ascending=False)\n",
    "        \n",
    "        # Score distribution\n",
    "        print(f\"\\nüìà PROPENSITY SCORE DISTRIBUTION\")\n",
    "        print(f\"   High Propensity (>0.7): {(prospects['donor_propensity_score'] > 0.7).sum():,}\")\n",
    "        print(f\"   Medium Propensity (0.5-0.7): {((prospects['donor_propensity_score'] > 0.5) & (prospects['donor_propensity_score'] <= 0.7)).sum():,}\")\n",
    "        print(f\"   Low Propensity (<0.5): {(prospects['donor_propensity_score'] <= 0.5).sum():,}\")\n",
    "        \n",
    "        score_column = 'donor_propensity_score'\n",
    "    else:\n",
    "        # Fallback: use engagement score\n",
    "        prospects = prospects.sort_values('engagement_score', ascending=False)\n",
    "        score_column = 'engagement_score'\n",
    "        print(\"‚ö†Ô∏è  Using engagement score as propensity proxy\")\n",
    "    \n",
    "    # Select top prospects\n",
    "    top_prospects = prospects.head(min(top_n, len(prospects))).copy()\n",
    "    \n",
    "    # Create prospect segments\n",
    "    def categorize_prospect(row):\n",
    "        categories = []\n",
    "        \n",
    "        if row.get('has_active_membership', 0) == 1:\n",
    "            categories.append('Member')\n",
    "        if row.get('is_volunteer', 0) == 1:\n",
    "            categories.append('Volunteer')\n",
    "        if row.get('attends_events', 0) == 1:\n",
    "            categories.append('Event Attendee')\n",
    "        if row.get('is_company', 0) == 1:\n",
    "            categories.append('Corporate')\n",
    "        if row.get('potential_high_capacity', 0) == 1:\n",
    "            categories.append('High Capacity')\n",
    "        \n",
    "        return ', '.join(categories) if categories else 'General Prospect'\n",
    "    \n",
    "    top_prospects['prospect_category'] = top_prospects.apply(categorize_prospect, axis=1)\n",
    "    \n",
    "    # Add suggested ask amount based on profile\n",
    "    def suggest_ask_amount(row):\n",
    "        base_ask = 25  # Default ask\n",
    "        \n",
    "        if row.get('is_company', 0) == 1:\n",
    "            base_ask = 250  # Corporate ask\n",
    "        elif row.get('total_membership_fees', 0) > 100:\n",
    "            base_ask = max(50, row.get('total_membership_fees', 0) * 0.5)  # 50% of membership fees\n",
    "        elif row.get('has_active_membership', 0) == 1:\n",
    "            base_ask = 50  # Member ask\n",
    "        elif row.get('is_volunteer', 0) == 1:\n",
    "            base_ask = 35  # Volunteer ask\n",
    "        \n",
    "        # Adjust based on propensity\n",
    "        if score_column in row and row[score_column] > 0.8:\n",
    "            base_ask *= 1.5  # Higher ask for high propensity\n",
    "        \n",
    "        return int(base_ask)\n",
    "    \n",
    "    top_prospects['suggested_ask'] = top_prospects.apply(suggest_ask_amount, axis=1)\n",
    "    \n",
    "    # Display top prospects\n",
    "    print(f\"\\nüèÜ TOP {len(top_prospects)} DONOR PROSPECTS\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    display_columns = [\n",
    "        'First Name', 'Last Name', 'Company Name', 'Account Type',\n",
    "        score_column, 'prospect_category', 'suggested_ask',\n",
    "        'City', 'State/Province', 'Email 1'\n",
    "    ]\n",
    "    \n",
    "    available_display_columns = [col for col in display_columns if col in top_prospects.columns]\n",
    "    \n",
    "    for idx, (_, prospect) in enumerate(top_prospects.iterrows(), 1):\n",
    "        name = f\"{prospect.get('First Name', '')} {prospect.get('Last Name', '')}\".strip()\n",
    "        if not name:\n",
    "            name = prospect.get('Company Name', 'Unknown')\n",
    "        \n",
    "        score = prospect.get(score_column, 0)\n",
    "        category = prospect.get('prospect_category', 'General')\n",
    "        ask = prospect.get('suggested_ask', 25)\n",
    "        location = f\"{prospect.get('City', '')}, {prospect.get('State/Province', '')}\".strip(', ')\n",
    "        \n",
    "        print(f\"{idx:2d}. {name:<25} | Score: {score:.3f} | {category:<20} | Ask: ${ask:>3} | {location}\")\n",
    "    \n",
    "    # Segment summary\n",
    "    print(f\"\\nüìä PROSPECT SEGMENT ANALYSIS\")\n",
    "    segment_summary = top_prospects['prospect_category'].value_counts()\n",
    "    \n",
    "    for category, count in segment_summary.items():\n",
    "        avg_score = top_prospects[top_prospects['prospect_category'] == category][score_column].mean()\n",
    "        avg_ask = top_prospects[top_prospects['prospect_category'] == category]['suggested_ask'].mean()\n",
    "        print(f\"   {category:<25} Count: {count:2d} | Avg Score: {avg_score:.3f} | Avg Ask: ${avg_ask:.0f}\")\n",
    "    \n",
    "    # Estimated revenue potential\n",
    "    total_ask_potential = top_prospects['suggested_ask'].sum()\n",
    "    estimated_conversion = 0.15  # Assume 15% conversion rate\n",
    "    estimated_revenue = total_ask_potential * estimated_conversion\n",
    "    \n",
    "    print(f\"\\nüí∞ REVENUE POTENTIAL ESTIMATE\")\n",
    "    print(f\"   Total Ask Amount: ${total_ask_potential:,}\")\n",
    "    print(f\"   Estimated Conversion Rate: {estimated_conversion*100:.0f}%\")\n",
    "    print(f\"   Estimated Revenue: ${estimated_revenue:,.0f}\")\n",
    "    \n",
    "    return top_prospects\n",
    "\n",
    "# Identify top prospects\n",
    "top_prospects = identify_top_prospects(donor_features, model_results, top_n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Strategic Recommendations\n",
    "\n",
    "Data-driven recommendations to increase donor acquisition and retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fundraising_strategy(df, top_prospects, analysis_results, model_results):\n",
    "    \"\"\"\n",
    "    Generate comprehensive fundraising strategy based on donor propensity analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üéØ STRATEGIC FUNDRAISING RECOMMENDATIONS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    # 1. High-priority prospect targeting\n",
    "    if top_prospects is not None and len(top_prospects) > 0:\n",
    "        high_propensity_prospects = len(top_prospects[top_prospects.get('donor_propensity_score', 0) > 0.7])\n",
    "        \n",
    "        recommendations.append({\n",
    "            'priority': 'HIGH',\n",
    "            'strategy': 'Targeted Prospect Cultivation',\n",
    "            'action': f'Launch personalized outreach to top {min(25, len(top_prospects))} prospects',\n",
    "            'details': f'Focus on {high_propensity_prospects} high-propensity prospects first',\n",
    "            'timeline': '30 days',\n",
    "            'expected_roi': f'Est. ${top_prospects[\"suggested_ask\"].head(25).sum() * 0.2:,.0f} revenue'\n",
    "        })\n",
    "    \n",
    "    # 2. Engagement-based conversion strategies  \n",
    "    if analysis_results:\n",
    "        if analysis_results.get('member_non_donors', 0) > 0:\n",
    "            recommendations.append({\n",
    "                'priority': 'HIGH',\n",
    "                'strategy': 'Member Conversion Campaign',\n",
    "                'action': f'Target {analysis_results[\"member_non_donors\"]} members who haven\\'t donated',\n",
    "                'details': 'Members already engaged - high conversion potential',\n",
    "                'timeline': '45 days',\n",
    "                'expected_roi': f'Members 3x more likely to donate'\n",
    "            })\n",
    "        \n",
    "        if analysis_results.get('volunteer_non_donors', 0) > 0:\n",
    "            recommendations.append({\n",
    "                'priority': 'MEDIUM',\n",
    "                'strategy': 'Volunteer Appreciation Campaign',\n",
    "                'action': f'Appreciation campaign for {analysis_results[\"volunteer_non_donors\"]} volunteers',\n",
    "                'details': 'Link volunteer impact to donation opportunity',\n",
    "                'timeline': '60 days', \n",
    "                'expected_roi': 'Volunteers show 2.5x higher propensity'\n",
    "            })\n",
    "        \n",
    "        if analysis_results.get('event_non_donors', 0) > 0:\n",
    "            recommendations.append({\n",
    "                'priority': 'MEDIUM',\n",
    "                'strategy': 'Event Follow-up Program',\n",
    "                'action': f'Post-event solicitation for {analysis_results[\"event_non_donors\"]} attendees',\n",
    "                'details': 'Strike while engagement is high - event follow-up',\n",
    "                'timeline': '90 days',\n",
    "                'expected_roi': 'Event attendees 40% more likely to give'\n",
    "            })\n",
    "    \n",
    "    # 3. Model-driven insights\n",
    "    if model_results and model_results.get('feature_importance') is not None:\n",
    "        top_features = model_results['feature_importance'].head(3)\n",
    "        \n",
    "        recommendations.append({\n",
    "            'priority': 'MEDIUM',\n",
    "            'strategy': 'Data-Driven Targeting',\n",
    "            'action': f'Focus on prospects with strong {top_features.iloc[0][\"feature\"]} indicators',\n",
    "            'details': f'Top predictors: {', '.join(top_features[\"feature\"].tolist())}',\n",
    "            'timeline': '60 days',\n",
    "            'expected_roi': f'ML model AUC: {model_results[\"best_model\"][\"auc_score\"]:.3f}'\n",
    "        })\n",
    "    \n",
    "    # 4. Ask amount optimization\n",
    "    if top_prospects is not None:\n",
    "        avg_suggested_ask = top_prospects['suggested_ask'].mean()\n",
    "        \n",
    "        recommendations.append({\n",
    "            'priority': 'LOW',\n",
    "            'strategy': 'Ask Amount Optimization',\n",
    "            'action': f'Use data-driven ask amounts (avg: ${avg_suggested_ask:.0f})',\n",
    "            'details': 'Personalized ask amounts based on capacity indicators',\n",
    "            'timeline': 'Ongoing',\n",
    "            'expected_roi': '20-30% increase in average gift size'\n",
    "        })\n",
    "    \n",
    "    # 5. Prospect research priorities\n",
    "    if top_prospects is not None:\n",
    "        corporate_prospects = len(top_prospects[top_prospects.get('is_company', 0) == 1])\n",
    "        high_capacity_prospects = len(top_prospects[top_prospects.get('potential_high_capacity', 0) == 1])\n",
    "        \n",
    "        if corporate_prospects > 0 or high_capacity_prospects > 0:\n",
    "            recommendations.append({\n",
    "                'priority': 'MEDIUM',\n",
    "                'strategy': 'Prospect Research Focus',\n",
    "                'action': f'Deep research on {corporate_prospects} corporate + {high_capacity_prospects} high-capacity prospects',\n",
    "                'details': 'Wealth screening and capacity assessment for major gift potential',\n",
    "                'timeline': '45 days',\n",
    "                'expected_roi': 'Identifies potential major gift prospects'\n",
    "            })\n",
    "    \n",
    "    # Display recommendations\n",
    "    print(f\"\\nüìã STRATEGIC ACTION PLAN\")\n",
    "    \n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        priority_emoji = 'üî¥' if rec['priority'] == 'HIGH' else 'üü°' if rec['priority'] == 'MEDIUM' else 'üü¢'\n",
    "        \n",
    "        print(f\"\\n{priority_emoji} STRATEGY {i}: {rec['strategy']} [{rec['priority']} PRIORITY]\")\n",
    "        print(f\"   Action: {rec['action']}\")\n",
    "        print(f\"   Details: {rec['details']}\")\n",
    "        print(f\"   Timeline: {rec['timeline']}\")\n",
    "        print(f\"   Expected ROI: {rec['expected_roi']}\")\n",
    "    \n",
    "    # Implementation timeline\n",
    "    print(f\"\\nüìÖ IMPLEMENTATION TIMELINE\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    high_priority = [r for r in recommendations if r['priority'] == 'HIGH']\n",
    "    medium_priority = [r for r in recommendations if r['priority'] == 'MEDIUM']\n",
    "    low_priority = [r for r in recommendations if r['priority'] == 'LOW']\n",
    "    \n",
    "    print(f\"üéØ IMMEDIATE (Next 30 days):\")\n",
    "    for rec in high_priority:\n",
    "        print(f\"   ‚Ä¢ {rec['strategy']}: {rec['action']}\")\n",
    "    \n",
    "    print(f\"\\nüìà SHORT-TERM (30-90 days):\")\n",
    "    for rec in medium_priority:\n",
    "        print(f\"   ‚Ä¢ {rec['strategy']}: {rec['action']}\")\n",
    "    \n",
    "    print(f\"\\nüîÑ ONGOING:\")\n",
    "    for rec in low_priority:\n",
    "        print(f\"   ‚Ä¢ {rec['strategy']}: {rec['action']}\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Generate strategy\n",
    "strategy_recommendations = generate_fundraising_strategy(\n",
    "    donor_features, top_prospects, analysis_results, model_results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization Dashboard\n",
    "\n",
    "Executive-ready visualizations for donor propensity insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_donor_propensity_dashboard(df, top_prospects, model_results):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization dashboard for donor propensity analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    if df is None or df.empty:\n",
    "        print(\"‚ùå No data available for visualization\")\n",
    "        return\n",
    "    \n",
    "    print(\"üìä Creating Donor Propensity Dashboard...\")\n",
    "    \n",
    "    # Create dashboard with multiple subplots\n",
    "    fig = plt.figure(figsize=(20, 16))\n",
    "    \n",
    "    # 1. Donor vs Non-Donor Comparison\n",
    "    plt.subplot(3, 3, 1)\n",
    "    donor_counts = df['is_donor'].value_counts()\n",
    "    labels = ['Non-Donors', 'Donors']\n",
    "    colors = ['#FF6B6B', '#4ECDC4']\n",
    "    \n",
    "    plt.pie(donor_counts.values, labels=labels, autopct='%1.1f%%', \n",
    "            colors=colors, startangle=90)\n",
    "    plt.title('Donor Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 2. Propensity Score Distribution\n",
    "    plt.subplot(3, 3, 2)\n",
    "    if 'donor_propensity_score' in df.columns:\n",
    "        non_donors = df[df['is_donor'] == 0]['donor_propensity_score']\n",
    "        donors = df[df['is_donor'] == 1]['donor_propensity_score']\n",
    "        \n",
    "        plt.hist([non_donors, donors], bins=30, alpha=0.7, \n",
    "                label=['Non-Donors', 'Donors'], color=['#FF6B6B', '#4ECDC4'])\n",
    "        plt.xlabel('Propensity Score')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Propensity Score Distribution', fontsize=14, fontweight='bold')\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Propensity Scores\\nNot Available', \n",
    "                ha='center', va='center', transform=plt.gca().transAxes, fontsize=12)\n",
    "        plt.title('Propensity Score Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 3. Engagement Score vs Donor Status\n",
    "    plt.subplot(3, 3, 3)\n",
    "    if 'engagement_score' in df.columns:\n",
    "        engagement_donor = df[df['is_donor'] == 1]['engagement_score']\n",
    "        engagement_non_donor = df[df['is_donor'] == 0]['engagement_score']\n",
    "        \n",
    "        plt.boxplot([engagement_non_donor.dropna(), engagement_donor.dropna()], \n",
    "                   labels=['Non-Donors', 'Donors'])\n",
    "        plt.ylabel('Engagement Score')\n",
    "        plt.title('Engagement Score by Donor Status', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 4. Account Type Analysis\n",
    "    plt.subplot(3, 3, 4)\n",
    "    if 'Account Type' in df.columns:\n",
    "        account_type_donor_rate = df.groupby('Account Type')['is_donor'].mean() * 100\n",
    "        account_type_donor_rate.plot(kind='bar', color='#45B7D1', alpha=0.7)\n",
    "        plt.ylabel('Donor Rate (%)')\n",
    "        plt.title('Donor Rate by Account Type', fontsize=14, fontweight='bold')\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "    # 5. Top Prospect Categories\n",
    "    plt.subplot(3, 3, 5)\n",
    "    if top_prospects is not None and 'prospect_category' in top_prospects.columns:\n",
    "        category_counts = top_prospects['prospect_category'].value_counts().head(6)\n",
    "        category_counts.plot(kind='barh', color='#96CEB4', alpha=0.8)\n",
    "        plt.xlabel('Number of Prospects')\n",
    "        plt.title('Top Prospect Categories', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 6. Feature Importance (if available)\n",
    "    plt.subplot(3, 3, 6)\n",
    "    if model_results and model_results.get('feature_importance') is not None:\n",
    "        top_features = model_results['feature_importance'].head(8)\n",
    "        plt.barh(range(len(top_features)), top_features['importance'], color='#FECA57')\n",
    "        plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "        plt.xlabel('Importance')\n",
    "        plt.title('Top Predictive Features', fontsize=14, fontweight='bold')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Feature Importance\\nNot Available', \n",
    "                ha='center', va='center', transform=plt.gca().transAxes, fontsize=12)\n",
    "        plt.title('Top Predictive Features', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 7. Engagement Factors Comparison\n",
    "    plt.subplot(3, 3, 7)\n",
    "    engagement_factors = ['attends_events', 'has_active_membership', 'is_volunteer', 'has_recent_activity']\n",
    "    available_factors = [f for f in engagement_factors if f in df.columns]\n",
    "    \n",
    "    if available_factors:\n",
    "        donor_rates = [df[df[factor] == 1]['is_donor'].mean() * 100 for factor in available_factors]\n",
    "        factor_labels = [f.replace('_', ' ').replace('has ', '').replace('is ', '').title() for f in available_factors]\n",
    "        \n",
    "        plt.bar(range(len(donor_rates)), donor_rates, color='#FF9FF3', alpha=0.8)\n",
    "        plt.xticks(range(len(factor_labels)), factor_labels, rotation=45, ha='right')\n",
    "        plt.ylabel('Donor Rate (%)')\n",
    "        plt.title('Donor Rate by Engagement Factor', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 8. Geographic Distribution of Top Prospects\n",
    "    plt.subplot(3, 3, 8)\n",
    "    if top_prospects is not None and 'State/Province' in top_prospects.columns:\n",
    "        top_states = top_prospects['State/Province'].value_counts().head(8)\n",
    "        if len(top_states) > 0:\n",
    "            top_states.plot(kind='pie', autopct='%1.0f%%', startangle=90)\n",
    "            plt.title('Top Prospects by State', fontsize=14, fontweight='bold')\n",
    "            plt.ylabel('')\n",
    "    \n",
    "    # 9. Suggested Ask Amount Distribution\n",
    "    plt.subplot(3, 3, 9)\n",
    "    if top_prospects is not None and 'suggested_ask' in top_prospects.columns:\n",
    "        ask_ranges = pd.cut(top_prospects['suggested_ask'], \n",
    "                           bins=[0, 25, 50, 100, 250, float('inf')],\n",
    "                           labels=['$1-25', '$26-50', '$51-100', '$101-250', '$250+'])\n",
    "        ask_distribution = ask_ranges.value_counts()\n",
    "        \n",
    "        ask_distribution.plot(kind='bar', color='#55A3FF', alpha=0.8)\n",
    "        plt.xlabel('Ask Amount Range')\n",
    "        plt.ylabel('Number of Prospects')\n",
    "        plt.title('Suggested Ask Amount Distribution', fontsize=14, fontweight='bold')\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save dashboard\n",
    "    dashboard_path = '/Users/mdassow/development/Neon_CRM_SDK/analysis/donor_propensity_dashboard.png'\n",
    "    plt.savefig(dashboard_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Dashboard saved: {dashboard_path}\")\n",
    "\n",
    "# Create dashboard\n",
    "create_donor_propensity_dashboard(donor_features, top_prospects, model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results & Next Steps\n",
    "\n",
    "Export actionable prospect lists and strategic recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_prospect_analysis(df, top_prospects, strategy_recommendations, model_results):\n",
    "    \"\"\"\n",
    "    Export comprehensive prospect analysis results.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üì§ EXPORTING ANALYSIS RESULTS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "    \n",
    "    # 1. Export top prospects to CSV\n",
    "    if top_prospects is not None and len(top_prospects) > 0:\n",
    "        prospect_export_columns = [\n",
    "            'Account ID', 'First Name', 'Last Name', 'Company Name', 'Account Type',\n",
    "            'Email 1', 'Phone 1', 'City', 'State/Province', 'Postal Code',\n",
    "            'donor_propensity_score', 'engagement_score', 'prospect_category', \n",
    "            'suggested_ask', 'has_active_membership', 'is_volunteer', 'attends_events'\n",
    "        ]\n",
    "        \n",
    "        available_export_columns = [col for col in prospect_export_columns if col in top_prospects.columns]\n",
    "        \n",
    "        prospects_file = f'/Users/mdassow/development/Neon_CRM_SDK/analysis/top_donor_prospects_{timestamp}.csv'\n",
    "        top_prospects[available_export_columns].to_csv(prospects_file, index=False)\n",
    "        print(f\"‚úÖ Exported {len(top_prospects)} prospects: {prospects_file}\")\n",
    "    \n",
    "    # 2. Create strategic summary report\n",
    "    report_content = f\"\"\"\n",
    "# DONOR PROPENSITY ANALYSIS - STRATEGIC REPORT\n",
    "Generated: {datetime.now().strftime('%B %d, %Y at %I:%M %p')}\n",
    "\n",
    "## EXECUTIVE SUMMARY\n",
    "\n",
    "### Key Findings\n",
    "\"\"\"\n",
    "    \n",
    "    if df is not None:\n",
    "        total_accounts = len(df)\n",
    "        donor_count = df['is_donor'].sum()\n",
    "        donor_rate = donor_count / total_accounts * 100\n",
    "        \n",
    "        report_content += f\"\"\"\n",
    "- **Total Accounts Analyzed**: {total_accounts:,}\n",
    "- **Current Donors**: {donor_count:,} ({donor_rate:.1f}%)\n",
    "- **Non-Donor Prospects**: {total_accounts - donor_count:,}\n",
    "\"\"\"\n",
    "        \n",
    "        if 'donor_propensity_score' in df.columns:\n",
    "            high_propensity_non_donors = len(df[(df['is_donor'] == 0) & (df['donor_propensity_score'] > 0.7)])\n",
    "            report_content += f\"- **High-Propensity Non-Donors**: {high_propensity_non_donors:,}\\n\"\n",
    "    \n",
    "    if model_results:\n",
    "        model_name = model_results.get('best_model_name', 'N/A')\n",
    "        auc_score = model_results.get('best_model', {}).get('auc_score', 0)\n",
    "        report_content += f\"- **Best Predictive Model**: {model_name} (AUC: {auc_score:.3f})\\n\"\n",
    "    \n",
    "    report_content += f\"\"\"\n",
    "\n",
    "### Strategic Recommendations\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    if strategy_recommendations:\n",
    "        high_priority_strategies = [r for r in strategy_recommendations if r['priority'] == 'HIGH']\n",
    "        \n",
    "        report_content += \"**HIGH PRIORITY ACTIONS:**\\n\"\n",
    "        for i, strategy in enumerate(high_priority_strategies, 1):\n",
    "            report_content += f\"\"\"\n",
    "{i}. **{strategy['strategy']}**\n",
    "   - Action: {strategy['action']}\n",
    "   - Timeline: {strategy['timeline']}\n",
    "   - Expected ROI: {strategy['expected_roi']}\n",
    "\"\"\"\n",
    "    \n",
    "    if top_prospects is not None:\n",
    "        total_ask_potential = top_prospects['suggested_ask'].sum()\n",
    "        avg_ask = top_prospects['suggested_ask'].mean()\n",
    "        \n",
    "        report_content += f\"\"\"\n",
    "\n",
    "### Revenue Opportunity\n",
    "\n",
    "- **Top {len(top_prospects)} Prospects Total Ask**: ${total_ask_potential:,}\n",
    "- **Average Suggested Ask**: ${avg_ask:.0f}\n",
    "- **Estimated Revenue** (15% conversion): ${total_ask_potential * 0.15:,.0f}\n",
    "- **Potential ROI**: 300-500% on cultivation investment\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Immediate (Next 30 days)**:\n",
    "   - Review top 25 prospects for personal outreach\n",
    "   - Develop personalized cultivation strategies\n",
    "   - Launch member/volunteer conversion campaigns\n",
    "\n",
    "2. **Short-term (30-90 days)**:\n",
    "   - Implement systematic prospect scoring\n",
    "   - Develop segment-specific messaging\n",
    "   - Track conversion rates and optimize\n",
    "\n",
    "3. **Long-term (3-12 months)**:\n",
    "   - Build ongoing propensity modeling pipeline\n",
    "   - Expand data collection for better predictions\n",
    "   - Develop retention strategies for new donors\n",
    "\n",
    "### Files Generated\n",
    "\n",
    "- `top_donor_prospects_{timestamp}.csv` - Detailed prospect list\n",
    "- `donor_propensity_dashboard.png` - Executive visualization dashboard\n",
    "- `donor_propensity_analysis.ipynb` - Complete technical analysis\n",
    "\n",
    "---\n",
    "*This analysis was generated using advanced machine learning techniques on comprehensive CRM data to identify the highest-value fundraising opportunities. Results should be validated through prospect research and combined with qualitative assessment.*\n",
    "\"\"\"\n",
    "    \n",
    "    # Save report\n",
    "    report_file = f'/Users/mdassow/development/Neon_CRM_SDK/analysis/donor_propensity_report_{timestamp}.md'\n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(report_content)\n",
    "    \n",
    "    print(f\"‚úÖ Strategic report exported: {report_file}\")\n",
    "    \n",
    "    # 3. Summary for immediate action\n",
    "    print(f\"\\nüéØ IMMEDIATE ACTIONS FOR DEVELOPMENT TEAM\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if top_prospects is not None:\n",
    "        print(f\"üìã PRIORITY PROSPECTS (Top 10):\")\n",
    "        for idx, (_, prospect) in enumerate(top_prospects.head(10).iterrows(), 1):\n",
    "            name = f\"{prospect.get('First Name', '')} {prospect.get('Last Name', '')}\".strip()\n",
    "            if not name:\n",
    "                name = prospect.get('Company Name', 'Unknown')\n",
    "            \n",
    "            score = prospect.get('donor_propensity_score', prospect.get('engagement_score', 0))\n",
    "            ask = prospect.get('suggested_ask', 25)\n",
    "            category = prospect.get('prospect_category', 'General')\n",
    "            \n",
    "            print(f\"   {idx:2d}. {name:<25} | Score: {score:.3f} | Ask: ${ask:>3} | {category}\")\n",
    "    \n",
    "    print(f\"\\nüìä Files ready for development team:\")\n",
    "    print(f\"   ‚Ä¢ Prospect list: top_donor_prospects_{timestamp}.csv\")\n",
    "    print(f\"   ‚Ä¢ Strategic report: donor_propensity_report_{timestamp}.md\")\n",
    "    print(f\"   ‚Ä¢ Dashboard: donor_propensity_dashboard.png\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ DONOR PROPENSITY ANALYSIS COMPLETE!\")\n",
    "    print(f\"üöÄ Ready to maximize fundraising ROI with data-driven insights!\")\n",
    "\n",
    "# Export results\n",
    "export_prospect_analysis(donor_features, top_prospects, strategy_recommendations, model_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
