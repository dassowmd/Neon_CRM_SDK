{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donor Segmentation & Growth Analysis\n",
    "\n",
    "**Strategic Analysis for Development Leadership**\n",
    "\n",
    "This analysis focuses on donor segmentation strategies and growth opportunities to maximize fundraising effectiveness and identify high-value donor prospects.\n",
    "\n",
    "## Analysis Objectives\n",
    "- Segment donors by giving capacity and behavior patterns\n",
    "- Identify growth opportunities within existing donor base\n",
    "- Analyze donor upgrade patterns and potential\n",
    "- Provide data-driven recommendations for cultivation strategies\n",
    "\n",
    "⚠️ **SAFETY NOTE**: This notebook contains only read-only operations for safety.\n",
    "Database-modifying operations are commented out to prevent accidental changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from neon_crm import NeonClient\n",
    "from neon_crm.governance import (\n",
    "    Permission, ResourceType, Role\n",
    ")\n",
    "\n",
    "# Configure visualization style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Initialize client\n",
    "client = NeonClient(\n",
    "    org_id=os.getenv(\"NEON_ORG_ID\"),\n",
    "    api_key=os.getenv(\"NEON_API_KEY\"),\n",
    "    default_role=\"fundraiser\")\n",
    "\n",
    "# Set up donor segmentation permissions\n",
    "\n",
    "print(f\"🚀 Neon CRM client initialized for donor segmentation analysis\")\n",
    "print(f\"📊 Analysis date: {datetime.now().strftime('%B %d, %Y')}\")\n",
    "print(f\"Environment: {client.environment}\")\n",
    "\n",
    "# Verify key permissions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection: Comprehensive Donor Dataset\n",
    "\n",
    "Collecting donor and donation data for advanced segmentation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_segmentation_data(client, years_back=5):\n",
    "    \"\"\"Collect comprehensive data for donor segmentation analysis.\"\"\"\n",
    "    \n",
    "    print(f\"📥 Collecting donor segmentation data for the past {years_back} years...\")\n",
    "    \n",
    "    # Calculate date range\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date.replace(year=end_date.year - years_back)\n",
    "    \n",
    "    print(f\"📅 Date range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # Collect all donations\n",
    "    donation_search = {\n",
    "        \"searchFields\": [\n",
    "            {\n",
    "                \"field\": \"Donation Date\",\n",
    "                \"operator\": \"GREATER_AND_EQUAL\",\n",
    "                \"value\": start_date.strftime('%Y-%m-%d')\n",
    "            }\n",
    "        ],\n",
    "        \"outputFields\": [\n",
    "            \"Donation ID\", \"Account ID\", \"Donation Amount\", \"Donation Date\", \"Campaign Name\",\n",
    "            \"Fund\", \"Source\", \"Tribute Type\", \"Anonymous Donation\",\n",
    "            \"2024 Eligible Donation Total\",\n",
    "            \"2023 Eligible Donation Total\"\n",
    "        ],\n",
    "        \"pagination\": {\"currentPage\": 0, \"pageSize\": 200}\n",
    "    }\n",
    "        \n",
    "    try:\n",
    "        donations = list(client.donations.search(donation_search, validate=False))\n",
    "        print(f\"✅ Collected {len(donations)} donations\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error collecting donations: {e}\")\n",
    "        return None, None\n",
    "        \n",
    "    # Get unique donor accounts\n",
    "    if donations:\n",
    "        donor_ids = list(set([d.get('Account ID') for d in donations if d.get('Account ID')]))\n",
    "        print(f\"👥 Identified {len(donor_ids)} unique donors\")\n",
    "    else:\n",
    "        print(\"⚠️ No donations found\")\n",
    "        return None, None\n",
    "        \n",
    "    # Collect donor profiles\n",
    "    account_search = {\n",
    "        \"searchFields\": [\n",
    "            {\"field\": \"Account Type\", \"operator\": \"EQUAL\", \"value\": \"INDIVIDUAL\"}\n",
    "        ],\n",
    "        \"outputFields\": [\n",
    "            \"Account ID\", \"First Name\", \"Last Name\", \"Company Name\",\n",
    "            \"Account Type\", \"Email 1\", \"City\", \"State/Province\", \"Country\",\n",
    "            \"Account Created Date/Time\", \"Account Last Modified Date/Time\"\n",
    "        ],\n",
    "        \"pagination\": {\"currentPage\": 0, \"pageSize\": 200}\n",
    "    }\n",
    "        \n",
    "    try:\n",
    "        all_accounts = list(client.accounts.search(account_search, validate=False))\n",
    "        # Filter to only donors in our dataset\n",
    "        donors = [acc for acc in all_accounts if acc.get('Account ID') in donor_ids]\n",
    "        print(f\"✅ Collected {len(donors)} donor profiles\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error collecting donor profiles: {e}\")\n",
    "        return donations, None\n",
    "    \n",
    "    return donations, donors\n",
    "\n",
    "# Collect the data\n",
    "donations_raw, donors_raw = collect_segmentation_data(client, years_back=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing and Feature Engineering\n",
    "\n",
    "Creating meaningful features for segmentation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def process_segmentation_data(donations_raw, donors_raw):\n",
    "    \"\"\"Process and engineer features for donor segmentation.\"\"\"\n",
    "    \n",
    "    if not donations_raw or not donors_raw:\n",
    "        print(\"❌ No data available for processing\")\n",
    "        return None\n",
    "    \n",
    "    print(\"🔄 Processing donor segmentation data...\")\n",
    "    \n",
    "    # Convert to DataFrames\n",
    "    donations_df = pd.DataFrame(donations_raw)\n",
    "    donors_df = pd.DataFrame(donors_raw)\n",
    "    \n",
    "    # Data cleaning\n",
    "    donations_df['Donation Amount'] = pd.to_numeric(donations_df['Donation Amount'], errors='coerce')\n",
    "    donations_df['Donation Date'] = pd.to_datetime(donations_df['Donation Date'], errors='coerce')\n",
    "    donations_df['Account ID'] = pd.to_numeric(donations_df['Account ID'], errors='coerce')\n",
    "    \n",
    "    donors_df['Account ID'] = pd.to_numeric(donors_df['Account ID'], errors='coerce')\n",
    "    donors_df['Account Created Date/Time'] = pd.to_datetime(donors_df['Account Created Date/Time'], errors='coerce')\n",
    "    \n",
    "    # Remove invalid data\n",
    "    donations_df = donations_df.dropna(subset=['Donation Amount', 'Donation Date', 'Account ID'])\n",
    "    donations_df = donations_df[donations_df['Donation Amount'] > 0]\n",
    "    \n",
    "    print(f\"✅ Processed {len(donations_df)} valid donations from {len(donors_df)} donors\")\n",
    "    \n",
    "    # Calculate RFM metrics (Recency, Frequency, Monetary)\n",
    "    current_date = datetime.now()\n",
    "    \n",
    "    rfm_data = donations_df.groupby('Account ID').agg({\n",
    "        'Donation Date': 'max',  # Most recent donation (Recency)\n",
    "        'Donation ID': 'count',  # Number of donations (Frequency)\n",
    "        'Donation Amount': ['sum', 'mean', 'std', 'min', 'max']  # Monetary metrics\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    rfm_data.columns = [\n",
    "        'last_donation_date', 'donation_frequency', 'total_donated',\n",
    "        'avg_donation', 'donation_std', 'min_donation', 'max_donation'\n",
    "    ]\n",
    "    \n",
    "    # Calculate recency in days\n",
    "    rfm_data['recency_days'] = (current_date - rfm_data['last_donation_date']).dt.days\n",
    "    \n",
    "    # Calculate donor tenure\n",
    "    first_donations = donations_df.groupby('Account ID')['Donation Date'].min()\n",
    "    rfm_data['first_donation_date'] = first_donations\n",
    "    rfm_data['tenure_days'] = (rfm_data['last_donation_date'] - rfm_data['first_donation_date']).dt.days\n",
    "    \n",
    "    # Calculate yearly giving trends\n",
    "    current_year = current_date.year\n",
    "    donations_df['year'] = donations_df['Donation Date'].dt.year\n",
    "    \n",
    "    # Calculate giving by year for trend analysis\n",
    "    yearly_giving = donations_df.groupby(['Account ID', 'year'])['Donation Amount'].sum().unstack(fill_value=0)\n",
    "    \n",
    "    # Calculate trend indicators\n",
    "    if current_year in yearly_giving.columns and (current_year - 1) in yearly_giving.columns:\n",
    "        rfm_data['gave_last_year'] = yearly_giving[current_year - 1] > 0\n",
    "        rfm_data['gave_this_year'] = yearly_giving[current_year] > 0\n",
    "        rfm_data['last_year_amount'] = yearly_giving[current_year - 1]\n",
    "        rfm_data['this_year_amount'] = yearly_giving[current_year]\n",
    "        \n",
    "        # Calculate year-over-year growth\n",
    "        rfm_data['yoy_growth'] = (\n",
    "            (rfm_data['this_year_amount'] - rfm_data['last_year_amount']) / \n",
    "            rfm_data['last_year_amount'].replace(0, np.nan)\n",
    "        ).fillna(0)\n",
    "    \n",
    "    # Fill missing values for std (single donors)\n",
    "    rfm_data['donation_std'] = rfm_data['donation_std'].fillna(0)\n",
    "    \n",
    "    # Add donor profile information\n",
    "    segmentation_data = rfm_data.merge(\n",
    "        donors_df[['Account ID', 'State/Province', 'Account Created Date/Time', ]],\n",
    "        on='Account ID',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Calculate donor age (time since first engagement)\n",
    "    segmentation_data['donor_age_days'] = (\n",
    "        current_date - segmentation_data['Account Created Date/Time']\n",
    "    ).dt.days\n",
    "    \n",
    "    print(f\"✅ Created segmentation dataset with {len(segmentation_data)} donors\")\n",
    "    print(f\"Features: {list(segmentation_data.columns)}\")\n",
    "    \n",
    "    return segmentation_data, donations_df\n",
    "\n",
    "# Process the data\n",
    "segmentation_data, donations_df = process_segmentation_data(donations_raw, donors_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RFM Analysis (Recency, Frequency, Monetary)\n",
    "\n",
    "Classic donor segmentation using RFM methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_rfm_segments(segmentation_data):\n",
    "    \"\"\"Create RFM segments for donor classification.\"\"\"\n",
    "    \n",
    "    if segmentation_data is None:\n",
    "        print(\"❌ No data available for RFM analysis\")\n",
    "        return None\n",
    "    \n",
    "    print(\"📊 Creating RFM segments...\")\n",
    "    \n",
    "    # Create a copy for RFM analysis\n",
    "    rfm_df = segmentation_data.copy()\n",
    "    \n",
    "    # Create RFM scores (1-5 scale, 5 being best)\n",
    "    # Recency: Lower days = better (reverse scoring)\n",
    "    rfm_df['r_score'] = pd.qcut(rfm_df['recency_days'].rank(method='first'), 5, labels=[5,4,3,2,1])\n",
    "    \n",
    "    # Frequency: Higher count = better\n",
    "    rfm_df['f_score'] = pd.qcut(rfm_df['donation_frequency'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
    "    \n",
    "    # Monetary: Higher amount = better\n",
    "    rfm_df['m_score'] = pd.qcut(rfm_df['total_donated'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
    "    \n",
    "    # Convert to numeric\n",
    "    rfm_df['r_score'] = rfm_df['r_score'].astype(int)\n",
    "    rfm_df['f_score'] = rfm_df['f_score'].astype(int) \n",
    "    rfm_df['m_score'] = rfm_df['m_score'].astype(int)\n",
    "    \n",
    "    # Create RFM combined score\n",
    "    rfm_df['rfm_score'] = rfm_df['r_score'].astype(str) + rfm_df['f_score'].astype(str) + rfm_df['m_score'].astype(str)\n",
    "    \n",
    "    # Define segment names based on RFM patterns\n",
    "    def categorize_rfm(row):\n",
    "        r, f, m = row['r_score'], row['f_score'], row['m_score']\n",
    "        \n",
    "        if r >= 4 and f >= 4 and m >= 4:\n",
    "            return \"Champions\"\n",
    "        elif r >= 3 and f >= 3 and m >= 3:\n",
    "            return \"Loyal Customers\"\n",
    "        elif r >= 4 and f <= 2:\n",
    "            return \"New Customers\"\n",
    "        elif r >= 3 and f >= 3 and m <= 2:\n",
    "            return \"Potential Loyalists\"\n",
    "        elif r >= 3 and f <= 2 and m <= 2:\n",
    "            return \"Promising\"\n",
    "        elif r <= 2 and f >= 4 and m >= 4:\n",
    "            return \"At Risk\"\n",
    "        elif r <= 2 and f >= 2 and m >= 2:\n",
    "            return \"Cannot Lose Them\"\n",
    "        elif r <= 2 and f <= 2 and m >= 3:\n",
    "            return \"Hibernating\"\n",
    "        else:\n",
    "            return \"Lost\"\n",
    "    \n",
    "    rfm_df['rfm_segment'] = rfm_df.apply(categorize_rfm, axis=1)\n",
    "    \n",
    "    # Calculate segment statistics\n",
    "    segment_summary = rfm_df.groupby('rfm_segment').agg({\n",
    "        'Account ID': 'count',\n",
    "        'total_donated': 'sum',\n",
    "        'avg_donation': 'mean',\n",
    "        'donation_frequency': 'mean',\n",
    "        'recency_days': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    segment_summary.columns = ['donor_count', 'total_revenue', 'avg_gift_size', 'avg_frequency', 'avg_recency']\n",
    "    segment_summary['revenue_percentage'] = (segment_summary['total_revenue'] / segment_summary['total_revenue'].sum() * 100).round(1)\n",
    "    \n",
    "    print(\"✅ RFM segmentation complete\")\n",
    "    print(f\"\\n📊 RFM Segment Summary:\")\n",
    "    print(segment_summary)\n",
    "    \n",
    "    return rfm_df, segment_summary\n",
    "\n",
    "# Create RFM segments\n",
    "if segmentation_data is not None:\n",
    "    rfm_df, segment_summary = create_rfm_segments(segmentation_data)\n",
    "else:\n",
    "    print(\"⚠️ Skipping RFM analysis - no data available\")\n",
    "    rfm_df, segment_summary = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Clustering Analysis\n",
    "\n",
    "Machine learning-based donor clustering for deeper insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def perform_clustering_analysis(segmentation_data, n_clusters=6):\n",
    "    \"\"\"Perform K-means clustering on donor behavior data.\"\"\"\n",
    "    \n",
    "    if segmentation_data is None:\n",
    "        print(\"❌ No data available for clustering analysis\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"🤖 Performing K-means clustering analysis with {n_clusters} clusters...\")\n",
    "    \n",
    "    # Select features for clustering\n",
    "    clustering_features = [\n",
    "        'recency_days', 'donation_frequency', 'total_donated',\n",
    "        'avg_donation', 'tenure_days', 'donor_age_days'\n",
    "    ]\n",
    "    \n",
    "    # Prepare data for clustering\n",
    "    cluster_data = segmentation_data[clustering_features].copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    cluster_data = cluster_data.fillna(cluster_data.median())\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    cluster_data_scaled = scaler.fit_transform(cluster_data)\n",
    "    \n",
    "    # Perform K-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(cluster_data_scaled)\n",
    "    \n",
    "    # Add cluster labels to original data\n",
    "    clustered_data = segmentation_data.copy()\n",
    "    clustered_data['cluster'] = cluster_labels\n",
    "    \n",
    "    # Analyze clusters\n",
    "    cluster_analysis = clustered_data.groupby('cluster').agg({\n",
    "        'Account ID': 'count',\n",
    "        'total_donated': ['sum', 'mean'],\n",
    "        'avg_donation': 'mean',\n",
    "        'donation_frequency': 'mean',\n",
    "        'recency_days': 'mean',\n",
    "        'tenure_days': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    cluster_analysis.columns = [\n",
    "        'donor_count', 'total_revenue', 'avg_total_donated',\n",
    "        'avg_gift_size', 'avg_frequency', 'avg_recency', 'avg_tenure'\n",
    "    ]\n",
    "    \n",
    "    # Add percentage of total revenue\n",
    "    cluster_analysis['revenue_percentage'] = (\n",
    "        cluster_analysis['total_revenue'] / cluster_analysis['total_revenue'].sum() * 100\n",
    "    ).round(1)\n",
    "    \n",
    "    # Name clusters based on characteristics\n",
    "    def name_cluster(row):\n",
    "        if row['avg_total_donated'] > cluster_analysis['avg_total_donated'].quantile(0.8):\n",
    "            if row['avg_recency'] < 180:\n",
    "                return \"Major Donors - Active\"\n",
    "            else:\n",
    "                return \"Major Donors - Lapsed\"\n",
    "        elif row['avg_frequency'] > cluster_analysis['avg_frequency'].quantile(0.7):\n",
    "            return \"Frequent Givers\"\n",
    "        elif row['avg_recency'] < 90:\n",
    "            return \"Recent Donors\"\n",
    "        elif row['avg_recency'] > 730:\n",
    "            return \"Dormant Donors\"\n",
    "        else:\n",
    "            return \"Occasional Donors\"\n",
    "    \n",
    "    cluster_analysis['cluster_name'] = cluster_analysis.apply(name_cluster, axis=1)\n",
    "    \n",
    "    print(\"✅ Clustering analysis complete\")\n",
    "    print(f\"\\n📊 Cluster Analysis Summary:\")\n",
    "    print(cluster_analysis[['cluster_name', 'donor_count', 'total_revenue', 'revenue_percentage', 'avg_recency']])\n",
    "    \n",
    "    return clustered_data, cluster_analysis\n",
    "\n",
    "# Perform clustering analysis\n",
    "if segmentation_data is not None:\n",
    "    clustered_data, cluster_analysis = perform_clustering_analysis(segmentation_data)\n",
    "else:\n",
    "    print(\"⚠️ Skipping clustering analysis - no data available\")\n",
    "    clustered_data, cluster_analysis = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Growth Opportunity Analysis\n",
    "\n",
    "Identify donors with upgrade potential and growth opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def analyze_growth_opportunities(segmentation_data, donations_df):\n",
    "    \"\"\"Identify growth opportunities within donor base.\"\"\"\n",
    "    \n",
    "    if segmentation_data is None or donations_df is None:\n",
    "        print(\"❌ No data available for growth analysis\")\n",
    "        return None\n",
    "    \n",
    "    print(\"📈 Analyzing donor growth opportunities...\")\n",
    "    \n",
    "    growth_analysis = segmentation_data.copy()\n",
    "    \n",
    "    # Calculate growth indicators\n",
    "    \n",
    "    # 1. Upgrade Potential Score\n",
    "    # Based on frequency, recency, and giving consistency\n",
    "\n",
    "    # More robust scoring function that handles duplicates\n",
    "    def create_robust_score(series, ascending=True, score_range=(1, 5)):\n",
    "        \"\"\"Create a robust 1-5 score handling duplicates and edge cases.\"\"\"\n",
    "        try:\n",
    "            # Try qcut first\n",
    "            if ascending:\n",
    "                return pd.qcut(series, 5, labels=list(range(*score_range, 1)), duplicates='drop').astype(float)\n",
    "            else:\n",
    "                return pd.qcut(series, 5, labels=list(range(score_range[1], score_range[0]-1, -1)), duplicates='drop').astype(float)\n",
    "        except ValueError:\n",
    "            # Fallback to percentile rank approach\n",
    "            percentile_rank = series.rank(pct=True)\n",
    "            if ascending:\n",
    "                return pd.cut(percentile_rank, bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0], \n",
    "                             labels=[1, 2, 3, 4, 5], include_lowest=True).astype(float)\n",
    "            else:\n",
    "                return pd.cut(percentile_rank, bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0], \n",
    "                             labels=[5, 4, 3, 2, 1], include_lowest=True).astype(float)\n",
    "\n",
    "    # Apply robust scoring\n",
    "    growth_analysis['frequency_score'] = create_robust_score(growth_analysis['donation_frequency'], ascending=True)\n",
    "    growth_analysis['recency_score'] = create_robust_score(growth_analysis['recency_days'], ascending=False)\n",
    "\n",
    "    # Calculate coefficient of variation for gift consistency\n",
    "    growth_analysis['gift_consistency'] = (\n",
    "        growth_analysis['donation_std'] / growth_analysis['avg_donation']\n",
    "    ).fillna(0)\n",
    "\n",
    "    # For consistency, lower variation = higher score (more consistent giving)\n",
    "    growth_analysis['consistency_score'] = create_robust_score(growth_analysis['gift_consistency'], ascending=False)\n",
    "    \n",
    "    # Combined upgrade potential score\n",
    "    growth_analysis['upgrade_potential'] = (\n",
    "        growth_analysis['frequency_score'] * 0.4 +\n",
    "        growth_analysis['recency_score'] * 0.4 +\n",
    "        growth_analysis['consistency_score'] * 0.2\n",
    "    )\n",
    "    \n",
    "    # 2. Capacity Indicators\n",
    "    # Donors who might be capable of larger gifts\n",
    "    \n",
    "    # Compare current giving to their maximum gift\n",
    "    growth_analysis['capacity_ratio'] = (\n",
    "        growth_analysis['avg_donation'] / growth_analysis['max_donation']\n",
    "    )\n",
    "    \n",
    "    # 3. Identify specific opportunity categories\n",
    "    def categorize_opportunity(row):\n",
    "        if row['recency_days'] <= 90 and row['donation_frequency'] >= 3:\n",
    "            if row['capacity_ratio'] < 0.7:\n",
    "                return \"High-Potential Upgrade\"\n",
    "            else:\n",
    "                return \"Loyal Donor - Sustain\"\n",
    "        elif row['recency_days'] <= 365 and row['donation_frequency'] >= 2:\n",
    "            return \"Mid-Level Cultivation\"\n",
    "        elif row['max_donation'] > row['avg_donation'] * 2:\n",
    "            return \"Capacity Upgrade Prospect\"\n",
    "        elif row['recency_days'] > 365:\n",
    "            if row['total_donated'] > growth_analysis['total_donated'].median():\n",
    "                return \"Reactivation Priority\"\n",
    "            else:\n",
    "                return \"Reactivation Standard\"\n",
    "        else:\n",
    "            return \"Standard Cultivation\"\n",
    "    \n",
    "    growth_analysis['opportunity_category'] = growth_analysis.apply(categorize_opportunity, axis=1)\n",
    "    \n",
    "    # 4. Year-over-year growth analysis\n",
    "    if 'yoy_growth' in growth_analysis.columns:\n",
    "        growth_analysis['growth_trend'] = pd.cut(\n",
    "            growth_analysis['yoy_growth'],\n",
    "            bins=[-np.inf, -0.5, -0.1, 0.1, 0.5, np.inf],\n",
    "            labels=['Declining', 'Slight Decline', 'Stable', 'Growing', 'Rapid Growth']\n",
    "        )\n",
    "    \n",
    "    # Summary by opportunity category\n",
    "    opportunity_summary = growth_analysis.groupby('opportunity_category').agg({\n",
    "        'Account ID': 'count',\n",
    "        'total_donated': 'sum',\n",
    "        'avg_donation': 'mean',\n",
    "        'upgrade_potential': 'mean',\n",
    "        'recency_days': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    opportunity_summary.columns = [\n",
    "        'donor_count', 'total_revenue', 'avg_gift_size', 'avg_upgrade_potential', 'avg_recency'\n",
    "    ]\n",
    "    \n",
    "    # Calculate potential revenue impact\n",
    "    opportunity_summary['revenue_percentage'] = (\n",
    "        opportunity_summary['total_revenue'] / opportunity_summary['total_revenue'].sum() * 100\n",
    "    ).round(1)\n",
    "    \n",
    "    print(\"✅ Growth opportunity analysis complete\")\n",
    "    print(f\"\\n📊 Growth Opportunity Summary:\")\n",
    "    print(opportunity_summary)\n",
    "    \n",
    "    # Identify top prospects\n",
    "    high_potential = growth_analysis[\n",
    "        (growth_analysis['upgrade_potential'] >= 4) &\n",
    "        (growth_analysis['recency_days'] <= 365)\n",
    "    ].sort_values(['upgrade_potential', 'total_donated'], ascending=[False, False])\n",
    "    \n",
    "    print(f\"\\n🎯 High-Potential Upgrade Prospects: {len(high_potential)} donors\")\n",
    "    if len(high_potential) > 0:\n",
    "        print(f\"Total revenue from high-potential donors: ${high_potential['total_donated'].sum():,.2f}\")\n",
    "        print(f\"Average gift size: ${high_potential['avg_donation'].mean():.2f}\")\n",
    "    \n",
    "    return growth_analysis, opportunity_summary, high_potential\n",
    "\n",
    "# Perform growth opportunity analysis\n",
    "if segmentation_data is not None and donations_df is not None:\n",
    "    growth_analysis, opportunity_summary, high_potential = analyze_growth_opportunities(segmentation_data, donations_df)\n",
    "else:\n",
    "    print(\"⚠️ Skipping growth analysis - no data available\")\n",
    "    growth_analysis, opportunity_summary, high_potential = None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization Dashboard\n",
    "\n",
    "Create comprehensive visualizations for segmentation insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_segmentation_dashboard(rfm_df, clustered_data, growth_analysis):\n",
    "    \"\"\"Create comprehensive segmentation visualization dashboard.\"\"\"\n",
    "    \n",
    "    if rfm_df is None:\n",
    "        print(\"❌ No data available for visualization\")\n",
    "        return\n",
    "    \n",
    "    print(\"📊 Creating segmentation dashboard...\")\n",
    "    \n",
    "    # Create a comprehensive dashboard\n",
    "    fig = plt.figure(figsize=(20, 16))\n",
    "    \n",
    "    # 1. RFM Segment Distribution\n",
    "    plt.subplot(3, 3, 1)\n",
    "    rfm_counts = rfm_df['rfm_segment'].value_counts()\n",
    "    plt.pie(rfm_counts.values, labels=rfm_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('RFM Segment Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 2. Revenue by RFM Segment\n",
    "    plt.subplot(3, 3, 2)\n",
    "    segment_revenue = rfm_df.groupby('rfm_segment')['total_donated'].sum().sort_values(ascending=True)\n",
    "    segment_revenue.plot(kind='barh', color='skyblue')\n",
    "    plt.title('Total Revenue by RFM Segment', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Total Revenue ($)')\n",
    "    \n",
    "    # 3. RFM Scatter Plot (Recency vs Frequency)\n",
    "    plt.subplot(3, 3, 3)\n",
    "    scatter = plt.scatter(rfm_df['recency_days'], rfm_df['donation_frequency'], \n",
    "                         c=rfm_df['total_donated'], cmap='viridis', alpha=0.6)\n",
    "    plt.colorbar(scatter, label='Total Donated ($)')\n",
    "    plt.xlabel('Recency (Days)')\n",
    "    plt.ylabel('Frequency (# Donations)')\n",
    "    plt.title('Donor RFM Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 4. Cluster Analysis (if available)\n",
    "    if clustered_data is not None:\n",
    "        plt.subplot(3, 3, 4)\n",
    "        cluster_counts = clustered_data['cluster'].value_counts().sort_index()\n",
    "        plt.bar(cluster_counts.index, cluster_counts.values, color='lightcoral')\n",
    "        plt.title('ML Cluster Distribution', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Cluster ID')\n",
    "        plt.ylabel('Number of Donors')\n",
    "    \n",
    "    # 5. Gift Size Distribution\n",
    "    plt.subplot(3, 3, 5)\n",
    "    plt.hist(rfm_df['avg_donation'], bins=30, alpha=0.7, color='green')\n",
    "    plt.axvline(rfm_df['avg_donation'].median(), color='red', linestyle='--', \n",
    "                label=f'Median: ${rfm_df[\"avg_donation\"].median():.2f}')\n",
    "    plt.title('Average Gift Size Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Average Gift Size ($)')\n",
    "    plt.ylabel('Number of Donors')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 6. Donor Tenure Analysis\n",
    "    plt.subplot(3, 3, 6)\n",
    "    tenure_bins = [0, 365, 730, 1095, 1825, 3650, float('inf')]\n",
    "    tenure_labels = ['<1 year', '1-2 years', '2-3 years', '3-5 years', '5-10 years', '10+ years']\n",
    "    rfm_df['tenure_category'] = pd.cut(rfm_df['tenure_days'], bins=tenure_bins, labels=tenure_labels)\n",
    "    tenure_counts = rfm_df['tenure_category'].value_counts()\n",
    "    tenure_counts.plot(kind='bar', color='orange', alpha=0.7)\n",
    "    plt.title('Donor Tenure Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Tenure Category')\n",
    "    plt.ylabel('Number of Donors')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 7. Growth Opportunity Analysis (if available)\n",
    "    if growth_analysis is not None:\n",
    "        plt.subplot(3, 3, 7)\n",
    "        opp_counts = growth_analysis['opportunity_category'].value_counts()\n",
    "        opp_counts.plot(kind='bar', color='purple', alpha=0.7)\n",
    "        plt.title('Growth Opportunity Categories', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Opportunity Type')\n",
    "        plt.ylabel('Number of Donors')\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "    # 8. Recency vs Monetary Heatmap\n",
    "    plt.subplot(3, 3, 8)\n",
    "    # Create recency and monetary bins for heatmap\n",
    "    rfm_df['recency_bin'] = pd.qcut(rfm_df['recency_days'], 5, labels=['Very Recent', 'Recent', 'Moderate', 'Old', 'Very Old'])\n",
    "    rfm_df['monetary_bin'] = pd.qcut(rfm_df['total_donated'], 5, labels=['Low', 'Low-Med', 'Medium', 'Med-High', 'High'])\n",
    "    \n",
    "    heatmap_data = rfm_df.groupby(['recency_bin', 'monetary_bin']).size().unstack(fill_value=0)\n",
    "    sns.heatmap(heatmap_data, annot=True, fmt='d', cmap='YlOrRd')\n",
    "    plt.title('Recency vs Monetary Heatmap', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Monetary Value')\n",
    "    plt.ylabel('Recency')\n",
    "    \n",
    "    # 9. Upgrade Potential Distribution (if available)\n",
    "    if growth_analysis is not None and 'upgrade_potential' in growth_analysis.columns:\n",
    "        plt.subplot(3, 3, 9)\n",
    "        plt.hist(growth_analysis['upgrade_potential'], bins=20, alpha=0.7, color='teal')\n",
    "        plt.axvline(growth_analysis['upgrade_potential'].median(), color='red', linestyle='--',\n",
    "                   label=f'Median: {growth_analysis[\"upgrade_potential\"].median():.2f}')\n",
    "        plt.title('Upgrade Potential Distribution', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Upgrade Potential Score')\n",
    "        plt.ylabel('Number of Donors')\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/Users/mdassow/development/Neon_CRM_SDK/analysis/donor_segmentation_dashboard.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Segmentation dashboard created and saved as 'donor_segmentation_dashboard.png'\")\n",
    "\n",
    "# Create the dashboard\n",
    "if rfm_df is not None:\n",
    "    create_segmentation_dashboard(rfm_df, clustered_data, growth_analysis)\n",
    "else:\n",
    "    print(\"⚠️ Skipping dashboard creation - no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Strategic Recommendations\n",
    "\n",
    "Data-driven recommendations for donor cultivation and growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_segmentation_recommendations(rfm_df, segment_summary, opportunity_summary, high_potential):\n",
    "    \"\"\"Generate strategic recommendations based on segmentation analysis.\"\"\"\n",
    "    \n",
    "    print(\"🎯 SEGMENTATION STRATEGIC RECOMMENDATIONS\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    if segment_summary is not None:\n",
    "        # 1. Champion Donors\n",
    "        if 'Champions' in segment_summary.index:\n",
    "            champions = segment_summary.loc['Champions']\n",
    "            recommendations.append({\n",
    "                'segment': 'Champions',\n",
    "                'priority': 'HIGH',\n",
    "                'strategy': 'VIP Stewardship Program',\n",
    "                'action': 'Create exclusive events, personal thank-you calls, and major gift pipeline',\n",
    "                'donors': int(champions['donor_count']),\n",
    "                'revenue': champions['total_revenue']\n",
    "            })\n",
    "        \n",
    "        # 2. At Risk Donors\n",
    "        if 'At Risk' in segment_summary.index:\n",
    "            at_risk = segment_summary.loc['At Risk']\n",
    "            recommendations.append({\n",
    "                'segment': 'At Risk',\n",
    "                'priority': 'HIGH',\n",
    "                'strategy': 'Urgent Retention Campaign',\n",
    "                'action': 'Personal outreach, impact reports, and re-engagement activities',\n",
    "                'donors': int(at_risk['donor_count']),\n",
    "                'revenue': at_risk['total_revenue']\n",
    "            })\n",
    "        \n",
    "        # 3. New Customers\n",
    "        if 'New Customers' in segment_summary.index:\n",
    "            new_customers = segment_summary.loc['New Customers']\n",
    "            recommendations.append({\n",
    "                'segment': 'New Customers',\n",
    "                'priority': 'MEDIUM',\n",
    "                'strategy': 'New Donor Journey',\n",
    "                'action': 'Welcome series, education about impact, and second gift cultivation',\n",
    "                'donors': int(new_customers['donor_count']),\n",
    "                'revenue': new_customers['total_revenue']\n",
    "            })\n",
    "    \n",
    "    if opportunity_summary is not None:\n",
    "        # 4. High-Potential Upgrades\n",
    "        if 'High-Potential Upgrade' in opportunity_summary.index:\n",
    "            upgrades = opportunity_summary.loc['High-Potential Upgrade']\n",
    "            recommendations.append({\n",
    "                'segment': 'High-Potential Upgrade',\n",
    "                'priority': 'HIGH',\n",
    "                'strategy': 'Capacity Building Campaign',\n",
    "                'action': 'Personal cultivation, capacity assessment, and major gift proposals',\n",
    "                'donors': int(upgrades['donor_count']),\n",
    "                'revenue': upgrades['total_revenue']\n",
    "            })\n",
    "        \n",
    "        # 5. Reactivation Priorities\n",
    "        if 'Reactivation Priority' in opportunity_summary.index:\n",
    "            reactivation = opportunity_summary.loc['Reactivation Priority']\n",
    "            recommendations.append({\n",
    "                'segment': 'Reactivation Priority',\n",
    "                'priority': 'MEDIUM',\n",
    "                'strategy': 'Win-Back Campaign',\n",
    "                'action': 'Targeted messaging about new initiatives and renewed impact',\n",
    "                'donors': int(reactivation['donor_count']),\n",
    "                'revenue': reactivation['total_revenue']\n",
    "            })\n",
    "    \n",
    "    # Display recommendations\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        priority_emoji = '🔴' if rec['priority'] == 'HIGH' else '🟡'\n",
    "        \n",
    "        print(f\"\\n{priority_emoji} RECOMMENDATION {i}: {rec['segment']} [{rec['priority']} PRIORITY]\")\n",
    "        print(f\"   Strategy: {rec['strategy']}\")\n",
    "        print(f\"   Action: {rec['action']}\")\n",
    "        print(f\"   Donors Affected: {rec['donors']:,}\")\n",
    "        print(f\"   Revenue Potential: ${rec['revenue']:,.2f}\")\n",
    "    \n",
    "    # High-potential prospects\n",
    "    if high_potential is not None and len(high_potential) > 0:\n",
    "        print(f\"\\n🎯 TOP UPGRADE PROSPECTS (Sample):\")\n",
    "        print(\"=\" * 35)\n",
    "        top_prospects = high_potential.head(10)\n",
    "        for idx, prospect in top_prospects.iterrows():\n",
    "            print(f\"   Account ID {prospect['Account ID']}: \")\n",
    "            print(f\"     • Total Given: ${prospect['total_donated']:,.2f}\")\n",
    "            print(f\"     • Avg Gift: ${prospect['avg_donation']:.2f}\")\n",
    "            print(f\"     • Frequency: {prospect['donation_frequency']} gifts\")\n",
    "            print(f\"     • Last Gift: {prospect['recency_days']} days ago\")\n",
    "            print(f\"     • Upgrade Score: {prospect['upgrade_potential']:.2f}\")\n",
    "            print()\n",
    "    \n",
    "    # Implementation roadmap\n",
    "    print(f\"\\n📋 IMPLEMENTATION ROADMAP\")\n",
    "    print(\"=\" * 30)\n",
    "    print(\"🔥 IMMEDIATE (30 days):\")\n",
    "    print(\"   • Launch urgent retention campaigns for at-risk major donors\")\n",
    "    print(\"   • Begin personal cultivation of top upgrade prospects\")\n",
    "    print(\"   • Implement VIP stewardship for Champions\")\n",
    "    \n",
    "    print(\"\\n⚡ SHORT-TERM (90 days):\")\n",
    "    print(\"   • Deploy new donor welcome sequences\")\n",
    "    print(\"   • Execute win-back campaigns for lapsed donors\")\n",
    "    print(\"   • Establish capacity assessment processes\")\n",
    "    \n",
    "    print(\"\\n🚀 LONG-TERM (6-12 months):\")\n",
    "    print(\"   • Build comprehensive donor journey mapping\")\n",
    "    print(\"   • Implement predictive analytics for prospect identification\")\n",
    "    print(\"   • Establish regular segmentation review cycles\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Generate recommendations\n",
    "if rfm_df is not None:\n",
    "    recommendations = generate_segmentation_recommendations(rfm_df, segment_summary, opportunity_summary, high_potential)\n",
    "else:\n",
    "    print(\"⚠️ No data available for recommendations\")\n",
    "    recommendations = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This donor segmentation and growth analysis provides:\n",
    "\n",
    "### ✅ Analysis Completed:\n",
    "- **RFM Segmentation**: Classic recency, frequency, monetary analysis\n",
    "- **Machine Learning Clustering**: Advanced behavioral segmentation\n",
    "- **Growth Opportunity Identification**: Upgrade prospects and cultivation priorities\n",
    "- **Strategic Recommendations**: Data-driven cultivation strategies\n",
    "\n",
    "### 🎯 Key Insights:\n",
    "- Donor behavior patterns and lifecycle stages\n",
    "- High-value prospect identification\n",
    "- Retention and reactivation opportunities\n",
    "- Revenue optimization strategies\n",
    "\n",
    "### 📊 Deliverables:\n",
    "- Comprehensive segmentation dashboard\n",
    "- Prioritized cultivation recommendations\n",
    "- High-potential prospect lists\n",
    "- Implementation roadmap\n",
    "\n",
    "### 🔧 Safety Features:\n",
    "- All operations are read-only\n",
    "- No database modifications\n",
    "- Robust error handling\n",
    "- Data validation throughout\n",
    "\n",
    "This analysis enables data-driven donor development strategies to maximize fundraising effectiveness and donor lifetime value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
