{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Batch Operations Performance Analysis with Neon CRM SDK\n",
    "\n",
    "This notebook demonstrates performance optimization techniques for batch operations using the Neon CRM SDK.\n",
    "\n",
    "‚ö†Ô∏è **SAFETY NOTE**: This notebook contains only read-only operations for safety.\n",
    "Database-modifying operations are commented out to prevent accidental changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T19:01:17.543111Z",
     "iopub.status.busy": "2025-10-03T19:01:17.542900Z",
     "iopub.status.idle": "2025-10-03T19:01:19.391858Z",
     "shell.execute_reply": "2025-10-03T19:01:19.391640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Neon CRM - Environment: production\n",
      "Timestamp: 2025-10-03 14:01:19.390413\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neon_crm import NeonClient, types\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Initialize the client\n",
    "client = NeonClient(\n",
    "    org_id=os.getenv('NEON_ORG_ID'),\n",
    "    api_key=os.getenv('NEON_API_KEY'),\n",
    ")\n",
    "\n",
    "print(f\"Connected to Neon CRM - Environment: {client.environment}\")\n",
    "print(f\"Timestamp: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Performance Measurement Utilities\n",
    "\n",
    "Helper functions to measure and analyze performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T19:01:19.393367Z",
     "iopub.status.busy": "2025-10-03T19:01:19.393255Z",
     "iopub.status.idle": "2025-10-03T19:01:19.397695Z",
     "shell.execute_reply": "2025-10-03T19:01:19.397508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Performance monitoring initialized\n"
     ]
    }
   ],
   "source": [
    "class PerformanceMonitor:\n",
    "    \"\"\"Monitor and analyze performance of batch operations.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.measurements = []\n",
    "    \n",
    "    def time_operation(self, operation_name: str, func, *args, **kwargs):\n",
    "        \"\"\"Time an operation and record the results.\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            success = True\n",
    "            error = None\n",
    "        except Exception as e:\n",
    "            result = None\n",
    "            success = False\n",
    "            error = str(e)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        \n",
    "        measurement = {\n",
    "            'operation': operation_name,\n",
    "            'start_time': start_time,\n",
    "            'end_time': end_time,\n",
    "            'duration': duration,\n",
    "            'success': success,\n",
    "            'error': error,\n",
    "            'timestamp': datetime.now()\n",
    "        }\n",
    "        \n",
    "        self.measurements.append(measurement)\n",
    "        \n",
    "        if success:\n",
    "            print(f\"‚úì {operation_name}: {duration:.2f}s\")\n",
    "        else:\n",
    "            print(f\"‚ùå {operation_name}: Failed after {duration:.2f}s - {error}\")\n",
    "        \n",
    "        return result, measurement\n",
    "    \n",
    "    def get_summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Get performance summary as DataFrame.\"\"\"\n",
    "        if not self.measurements:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(self.measurements)\n",
    "        return df\n",
    "    \n",
    "    def analyze_performance(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze performance metrics.\"\"\"\n",
    "        df = self.get_summary()\n",
    "        \n",
    "        if df.empty:\n",
    "            return {}\n",
    "        \n",
    "        # Filter successful operations for analysis\n",
    "        successful_ops = df[df['success'] == True]\n",
    "        \n",
    "        if successful_ops.empty:\n",
    "            return {'total_operations': len(df), 'successful_operations': 0}\n",
    "        \n",
    "        analysis = {\n",
    "            'total_operations': len(df),\n",
    "            'successful_operations': len(successful_ops),\n",
    "            'success_rate': len(successful_ops) / len(df) * 100,\n",
    "            'avg_duration': successful_ops['duration'].mean(),\n",
    "            'min_duration': successful_ops['duration'].min(),\n",
    "            'max_duration': successful_ops['duration'].max(),\n",
    "            'total_time': successful_ops['duration'].sum(),\n",
    "            'operations_per_second': len(successful_ops) / successful_ops['duration'].sum()\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "\n",
    "# Initialize performance monitor\n",
    "perf_monitor = PerformanceMonitor()\n",
    "print(\"üìä Performance monitoring initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Single vs Batch Request Performance\n",
    "\n",
    "Compare performance of individual requests vs batch operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T19:01:19.398722Z",
     "iopub.status.busy": "2025-10-03T19:01:19.398662Z",
     "iopub.status.idle": "2025-10-03T19:01:21.469545Z",
     "shell.execute_reply": "2025-10-03T19:01:21.469117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing single request performance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì List Accounts (Single Request): 0.27s\n",
      "Retrieved 50 accounts\n",
      "\n",
      "üîç Testing individual account retrievals...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Get Account 1 (ID: 5602): 1.19s\n",
      "‚úì Get Account 2 (ID: 3133): 0.15s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Get Account 3 (ID: 2228): 0.15s\n",
      "‚úì Get Account 4 (ID: 5093): 0.15s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Get Account 5 (ID: 4781): 0.17s\n"
     ]
    }
   ],
   "source": [
    "# Test single request performance\n",
    "print(\"üîç Testing single request performance...\")\n",
    "\n",
    "# Get some accounts for testing\n",
    "accounts_result, measurement = perf_monitor.time_operation(\n",
    "    \"List Accounts (Single Request)\",\n",
    "    lambda: list(client.accounts.list(page_size=100, limit=50, user_type=types.UserType.INDIVIDUAL))\n",
    ")\n",
    "\n",
    "if accounts_result:\n",
    "    print(f\"Retrieved {len(accounts_result)} accounts\")\n",
    "    \n",
    "    # Test individual account retrievals\n",
    "    print(\"\\nüîç Testing individual account retrievals...\")\n",
    "    \n",
    "    sample_accounts = accounts_result[:5]  # Test with first 5 accounts\n",
    "    \n",
    "    for i, account in enumerate(sample_accounts, 1):\n",
    "        account_id = account.get('accountId')\n",
    "        \n",
    "        if account_id:\n",
    "            account_detail, _ = perf_monitor.time_operation(\n",
    "                f\"Get Account {i} (ID: {account_id})\",\n",
    "                client.accounts.get,\n",
    "                account_id\n",
    "            )\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Account {i}: No account ID found\")\n",
    "else:\n",
    "    print(\"‚ùå Could not retrieve accounts for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3. Pagination Strategy Performance\n",
    "\n",
    "Test different pagination strategies to find optimal page sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T19:01:21.471434Z",
     "iopub.status.busy": "2025-10-03T19:01:21.471286Z",
     "iopub.status.idle": "2025-10-03T19:01:24.607323Z",
     "shell.execute_reply": "2025-10-03T19:01:24.606790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Testing pagination strategy performance...\n",
      "\n",
      "üîç Testing page size: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì List Accounts (page_size=25): 0.96s\n",
      "  ‚úì Retrieved 100 records at 104.0 records/second\n",
      "\n",
      "üîç Testing page size: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì List Accounts (page_size=50): 0.38s\n",
      "  ‚úì Retrieved 100 records at 264.1 records/second\n",
      "\n",
      "üîç Testing page size: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì List Accounts (page_size=100): 1.62s\n",
      "  ‚úì Retrieved 100 records at 61.7 records/second\n",
      "\n",
      "üîç Testing page size: 200\n",
      "‚úì List Accounts (page_size=200): 0.16s\n",
      "  ‚úì Retrieved 100 records at 627.9 records/second\n",
      "\n",
      "üìä Pagination Performance Summary:\n",
      " page_size  total_records  duration  records_per_second\n",
      "        25            100  0.961431          104.011647\n",
      "        50            100  0.378656          264.092009\n",
      "       100            100  1.620646           61.703790\n",
      "       200            100  0.159251          627.938702\n",
      "\n",
      "üéØ Optimal page size: 200 (627.9 records/second)\n"
     ]
    }
   ],
   "source": [
    "# Test different page sizes for optimal performance\n",
    "print(\"üìÑ Testing pagination strategy performance...\")\n",
    "\n",
    "page_sizes = [25, 50, 100, 200]\n",
    "pagination_results = []\n",
    "\n",
    "for page_size in page_sizes:\n",
    "    print(f\"\\nüîç Testing page size: {page_size}\")\n",
    "    \n",
    "    # Test accounts list with different page sizes\n",
    "    accounts_result, measurement = perf_monitor.time_operation(\n",
    "        f\"List Accounts (page_size={page_size})\",\n",
    "        lambda ps=page_size: list(client.accounts.list(page_size=ps, limit=100, user_type=types.UserType.INDIVIDUAL))\n",
    "    )\n",
    "    \n",
    "    if accounts_result:\n",
    "        records_per_second = len(accounts_result) / measurement['duration']\n",
    "        pagination_results.append({\n",
    "            'page_size': page_size,\n",
    "            'total_records': len(accounts_result),\n",
    "            'duration': measurement['duration'],\n",
    "            'records_per_second': records_per_second,\n",
    "            'success': True\n",
    "        })\n",
    "        print(f\"  ‚úì Retrieved {len(accounts_result)} records at {records_per_second:.1f} records/second\")\n",
    "    else:\n",
    "        pagination_results.append({\n",
    "            'page_size': page_size,\n",
    "            'total_records': 0,\n",
    "            'duration': measurement['duration'],\n",
    "            'records_per_second': 0,\n",
    "            'success': False\n",
    "        })\n",
    "\n",
    "# Analyze pagination performance\n",
    "if pagination_results:\n",
    "    pagination_df = pd.DataFrame(pagination_results)\n",
    "    successful_pagination = pagination_df[pagination_df['success'] == True]\n",
    "    \n",
    "    if not successful_pagination.empty:\n",
    "        print(\"\\nüìä Pagination Performance Summary:\")\n",
    "        print(successful_pagination[['page_size', 'total_records', 'duration', 'records_per_second']].to_string(index=False))\n",
    "        \n",
    "        # Find optimal page size\n",
    "        optimal_page_size = successful_pagination.loc[successful_pagination['records_per_second'].idxmax()]\n",
    "        print(f\"\\nüéØ Optimal page size: {optimal_page_size['page_size']} ({optimal_page_size['records_per_second']:.1f} records/second)\")\n",
    "    else:\n",
    "        print(\"‚ùå No successful pagination tests\")\n",
    "else:\n",
    "    print(\"‚ùå No pagination results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 4. Search Operation Performance\n",
    "\n",
    "Analyze performance of search operations with different criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T19:01:24.610232Z",
     "iopub.status.busy": "2025-10-03T19:01:24.610026Z",
     "iopub.status.idle": "2025-10-03T19:03:56.036132Z",
     "shell.execute_reply": "2025-10-03T19:03:56.027638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing search operation performance...\n",
      "\n",
      "üîç Simple Account Search...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Simple Account Search: 125.81s\n",
      "  ‚úì Found 3694 records at 29.4 records/second\n",
      "\n",
      "üîç Donation Search by Date Range...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Donation Search by Date Range: 25.58s\n",
      "  ‚úì Found 2629 records at 102.8 records/second\n",
      "\n",
      "üìä Search Performance Summary:\n",
      "                    test_name  total_records   duration  records_per_second\n",
      "        Simple Account Search           3694 125.810817           29.361545\n",
      "Donation Search by Date Range           2629  25.575025          102.795599\n"
     ]
    }
   ],
   "source": [
    "# Test search operation performance\n",
    "print(\"üîç Testing search operation performance...\")\n",
    "\n",
    "# Test different search strategies\n",
    "search_tests = [\n",
    "    {\n",
    "        'name': 'Simple Account Search',\n",
    "        'resource': 'accounts',\n",
    "        'request': {\n",
    "            'searchFields': [\n",
    "                {'field': 'Account Type', 'operator': 'EQUAL', 'value': 'Individual'}\n",
    "            ],\n",
    "            'outputFields': ['Account ID', 'First Name', 'Last Name', 'Email 1'],\n",
    "            'pagination': {'currentPage': 0, 'pageSize': 200}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'Donation Search by Date Range',\n",
    "        'resource': 'donations',\n",
    "        'request': {\n",
    "            'searchFields': [\n",
    "                {'field': 'Donation Date', 'operator': 'GREATER_THAN', 'value': '2023-01-01'}\n",
    "            ],\n",
    "            'outputFields': ['Donation ID', 'Account ID', 'Donation Amount', 'Donation Date'],\n",
    "            'pagination': {'currentPage': 0, 'pageSize': 200}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for test in search_tests:\n",
    "    print(f\"\\nüîç {test['name']}...\")\n",
    "    \n",
    "    try:\n",
    "        if test['resource'] == 'accounts':\n",
    "            search_result, measurement = perf_monitor.time_operation(\n",
    "                test['name'],\n",
    "                lambda: list(client.accounts.search(test['request'], validate=False))\n",
    "            )\n",
    "        elif test['resource'] == 'donations':\n",
    "            search_result, measurement = perf_monitor.time_operation(\n",
    "                test['name'],\n",
    "                lambda: list(client.donations.search(test['request'], validate=False))\n",
    "            )\n",
    "        \n",
    "        if search_result:\n",
    "            records_per_second = len(search_result) / measurement['duration']\n",
    "            search_results.append({\n",
    "                'test_name': test['name'],\n",
    "                'resource': test['resource'],\n",
    "                'total_records': len(search_result),\n",
    "                'duration': measurement['duration'],\n",
    "                'records_per_second': records_per_second,\n",
    "                'success': True\n",
    "            })\n",
    "            print(f\"  ‚úì Found {len(search_result)} records at {records_per_second:.1f} records/second\")\n",
    "        else:\n",
    "            search_results.append({\n",
    "                'test_name': test['name'],\n",
    "                'resource': test['resource'],\n",
    "                'total_records': 0,\n",
    "                'duration': measurement['duration'],\n",
    "                'records_per_second': 0,\n",
    "                'success': False\n",
    "            })\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå {test['name']} failed: {e}\")\n",
    "        search_results.append({\n",
    "            'test_name': test['name'],\n",
    "            'resource': test['resource'],\n",
    "            'total_records': 0,\n",
    "            'duration': 0,\n",
    "            'records_per_second': 0,\n",
    "            'success': False\n",
    "        })\n",
    "\n",
    "# Display search performance results\n",
    "if search_results:\n",
    "    search_df = pd.DataFrame(search_results)\n",
    "    successful_searches = search_df[search_df['success'] == True]\n",
    "    \n",
    "    if not successful_searches.empty:\n",
    "        print(\"\\nüìä Search Performance Summary:\")\n",
    "        print(successful_searches[['test_name', 'total_records', 'duration', 'records_per_second']].to_string(index=False))\n",
    "    else:\n",
    "        print(\"‚ùå No successful search operations\")\n",
    "else:\n",
    "    print(\"‚ùå No search results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 5. Concurrent Operations Performance\n",
    "\n",
    "Test performance improvements from concurrent operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T19:03:56.040113Z",
     "iopub.status.busy": "2025-10-03T19:03:56.039960Z",
     "iopub.status.idle": "2025-10-03T19:09:35.602269Z",
     "shell.execute_reply": "2025-10-03T19:09:35.601070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÄ Testing concurrent operations performance...\n",
      "\n",
      "üìù Sequential execution...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Sequential Search 1: 174.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Sequential Search 2: 0.26s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Sequential Search 3: 78.25s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Sequential Search 4: 86.98s\n",
      "‚úì Sequential: 11140 total records in 339.54s\n",
      "\n",
      "üîÄ Concurrent execution...\n",
      "‚úì Concurrent: 0 total records in 0.01s\n",
      "\n",
      "üìä Concurrency Performance Analysis:\n",
      "Sequential Time: 339.54s\n",
      "Concurrent Time: 0.01s\n",
      "Speedup: 38124.89x\n",
      "Efficiency: 953122.2%\n",
      "üéØ Concurrent operations are 38124.89x faster!\n"
     ]
    }
   ],
   "source": [
    "# Test concurrent operations\n",
    "print(\"üîÄ Testing concurrent operations performance...\")\n",
    "\n",
    "def perform_account_search(search_criteria):\n",
    "    \"\"\"Perform an account search operation.\"\"\"\n",
    "    try:\n",
    "        request = {\n",
    "            'searchFields': search_criteria,\n",
    "            'outputFields': ['Account ID', 'First Name', 'Last Name'],\n",
    "            'pagination': {'currentPage': 0, 'pageSize': 200}\n",
    "        }\n",
    "        result = list(client.accounts.search(request, validate=False))\n",
    "        return len(result)\n",
    "    except Exception as e:\n",
    "        return 0\n",
    "\n",
    "# Define multiple search criteria for concurrent testing\n",
    "concurrent_searches = [\n",
    "    [{'field': 'Account Type', 'operator': 'EQUAL', 'value': 'Individual'}],\n",
    "    [{'field': 'Account Type', 'operator': 'EQUAL', 'value': 'Organization'}],\n",
    "    [{'field': 'First Name', 'operator': 'NOT_BLANK', 'value': ''}],\n",
    "    [{'field': 'Last Name', 'operator': 'NOT_BLANK', 'value': ''}],\n",
    "]\n",
    "\n",
    "# Sequential execution\n",
    "print(\"\\nüìù Sequential execution...\")\n",
    "sequential_results = []\n",
    "sequential_start = time.time()\n",
    "\n",
    "for i, criteria in enumerate(concurrent_searches, 1):\n",
    "    result_count, measurement = perf_monitor.time_operation(\n",
    "        f\"Sequential Search {i}\",\n",
    "        perform_account_search,\n",
    "        criteria\n",
    "    )\n",
    "    sequential_results.append(result_count)\n",
    "\n",
    "sequential_total_time = time.time() - sequential_start\n",
    "sequential_total_records = sum(sequential_results)\n",
    "\n",
    "print(f\"‚úì Sequential: {sequential_total_records} total records in {sequential_total_time:.2f}s\")\n",
    "\n",
    "# Concurrent execution\n",
    "print(\"\\nüîÄ Concurrent execution...\")\n",
    "concurrent_start = time.time()\n",
    "concurrent_results = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    # Submit all searches concurrently\n",
    "    future_to_criteria = {\n",
    "        executor.submit(perform_account_search, criteria): criteria \n",
    "        for criteria in concurrent_searches\n",
    "    }\n",
    "    \n",
    "    # Collect results as they complete\n",
    "    for future in as_completed(future_to_criteria):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            concurrent_results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Concurrent search failed: {e}\")\n",
    "            concurrent_results.append(0)\n",
    "\n",
    "concurrent_total_time = time.time() - concurrent_start\n",
    "concurrent_total_records = sum(concurrent_results)\n",
    "\n",
    "print(f\"‚úì Concurrent: {concurrent_total_records} total records in {concurrent_total_time:.2f}s\")\n",
    "\n",
    "# Compare performance\n",
    "if sequential_total_time > 0 and concurrent_total_time > 0:\n",
    "    speedup = sequential_total_time / concurrent_total_time\n",
    "    efficiency = (speedup / len(concurrent_searches)) * 100\n",
    "    \n",
    "    print(f\"\\nüìä Concurrency Performance Analysis:\")\n",
    "    print(f\"Sequential Time: {sequential_total_time:.2f}s\")\n",
    "    print(f\"Concurrent Time: {concurrent_total_time:.2f}s\")\n",
    "    print(f\"Speedup: {speedup:.2f}x\")\n",
    "    print(f\"Efficiency: {efficiency:.1f}%\")\n",
    "    \n",
    "    if speedup > 1.0:\n",
    "        print(f\"üéØ Concurrent operations are {speedup:.2f}x faster!\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Sequential operations performed better in this test\")\n",
    "else:\n",
    "    print(\"‚ùå Could not compare performance - insufficient timing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 6. Memory Usage Analysis\n",
    "\n",
    "Monitor memory usage during batch operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T19:09:35.609776Z",
     "iopub.status.busy": "2025-10-03T19:09:35.609577Z",
     "iopub.status.idle": "2025-10-03T19:09:38.719878Z",
     "shell.execute_reply": "2025-10-03T19:09:38.719593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Memory usage analysis...\n",
      "\n",
      "üíæ Testing memory usage with batch size: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Retrieved 50 records\n",
      "  üíæ Memory used: 0.2 MB (4.8 KB per record)\n",
      "\n",
      "üíæ Testing memory usage with batch size: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Retrieved 100 records\n",
      "  üíæ Memory used: 0.2 MB (1.6 KB per record)\n",
      "\n",
      "üíæ Testing memory usage with batch size: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Retrieved 200 records\n",
      "  üíæ Memory used: 0.4 MB (2.2 KB per record)\n",
      "\n",
      "üíæ Testing memory usage with batch size: 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Retrieved 500 records\n",
      "  üíæ Memory used: 0.4 MB (0.9 KB per record)\n",
      "\n",
      "üìä Memory Usage Analysis:\n",
      " batch_size  records_retrieved  memory_used_mb  memory_per_record_kb  duration\n",
      "         50                 50        0.234375                 4.800  0.260314\n",
      "        100                100        0.156250                 1.600  0.405141\n",
      "        200                200        0.421875                 2.160  0.615297\n",
      "        500                500        0.421875                 0.864  1.168301\n",
      "\n",
      "üéØ Most memory-efficient batch size: 500 (0.9 KB per record)\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import gc\n",
    "\n",
    "# Memory usage monitoring\n",
    "print(\"üíæ Memory usage analysis...\")\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage in MB.\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024  # Convert to MB\n",
    "\n",
    "# Test memory usage with different batch sizes\n",
    "batch_sizes = [50, 100, 200, 500]\n",
    "memory_results = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"\\nüíæ Testing memory usage with batch size: {batch_size}\")\n",
    "    \n",
    "    # Clear memory before test\n",
    "    gc.collect()\n",
    "    initial_memory = get_memory_usage()\n",
    "    \n",
    "    try:\n",
    "        # Perform batch operation\n",
    "        start_time = time.time()\n",
    "        accounts = list(client.accounts.list(page_size=batch_size, limit=batch_size, user_type=types.UserType.INDIVIDUAL))\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        peak_memory = get_memory_usage()\n",
    "        memory_used = peak_memory - initial_memory\n",
    "        \n",
    "        memory_results.append({\n",
    "            'batch_size': batch_size,\n",
    "            'records_retrieved': len(accounts),\n",
    "            'initial_memory_mb': initial_memory,\n",
    "            'peak_memory_mb': peak_memory,\n",
    "            'memory_used_mb': memory_used,\n",
    "            'memory_per_record_kb': (memory_used * 1024) / len(accounts) if len(accounts) > 0 else 0,\n",
    "            'duration': duration,\n",
    "            'success': True\n",
    "        })\n",
    "        \n",
    "        print(f\"  ‚úì Retrieved {len(accounts)} records\")\n",
    "        print(f\"  üíæ Memory used: {memory_used:.1f} MB ({(memory_used * 1024) / len(accounts):.1f} KB per record)\")\n",
    "        \n",
    "        # Clear memory after test\n",
    "        del accounts\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Failed: {e}\")\n",
    "        memory_results.append({\n",
    "            'batch_size': batch_size,\n",
    "            'records_retrieved': 0,\n",
    "            'initial_memory_mb': initial_memory,\n",
    "            'peak_memory_mb': get_memory_usage(),\n",
    "            'memory_used_mb': 0,\n",
    "            'memory_per_record_kb': 0,\n",
    "            'duration': 0,\n",
    "            'success': False\n",
    "        })\n",
    "\n",
    "# Display memory analysis results\n",
    "if memory_results:\n",
    "    memory_df = pd.DataFrame(memory_results)\n",
    "    successful_memory = memory_df[memory_df['success'] == True]\n",
    "    \n",
    "    if not successful_memory.empty:\n",
    "        print(\"\\nüìä Memory Usage Analysis:\")\n",
    "        display_cols = ['batch_size', 'records_retrieved', 'memory_used_mb', 'memory_per_record_kb', 'duration']\n",
    "        print(successful_memory[display_cols].to_string(index=False))\n",
    "        \n",
    "        # Find most memory-efficient batch size\n",
    "        if successful_memory['memory_per_record_kb'].sum() > 0:\n",
    "            most_efficient = successful_memory.loc[successful_memory['memory_per_record_kb'].idxmin()]\n",
    "            print(f\"\\nüéØ Most memory-efficient batch size: {most_efficient['batch_size']} ({most_efficient['memory_per_record_kb']:.1f} KB per record)\")\n",
    "    else:\n",
    "        print(\"‚ùå No successful memory tests\")\n",
    "else:\n",
    "    print(\"‚ùå No memory results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 7. Performance Visualization\n",
    "\n",
    "Create visualizations of performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T19:09:38.721803Z",
     "iopub.status.busy": "2025-10-03T19:09:38.721712Z",
     "iopub.status.idle": "2025-10-03T19:09:38.814341Z",
     "shell.execute_reply": "2025-10-03T19:09:38.814120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Creating performance visualizations...\n",
      "‚úì Performance visualizations created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0y/88x520cx00v_hrgplch4yg3m0000gn/T/ipykernel_90806/3613076820.py:77: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Create performance visualizations\n",
    "print(\"üìà Creating performance visualizations...\")\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Neon CRM SDK - Batch Operations Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Pagination Performance\n",
    "if 'pagination_df' in locals() and not pagination_df.empty:\n",
    "    successful_pagination = pagination_df[pagination_df['success'] == True]\n",
    "    if not successful_pagination.empty:\n",
    "        axes[0, 0].bar(successful_pagination['page_size'], successful_pagination['records_per_second'])\n",
    "        axes[0, 0].set_title('Pagination Performance')\n",
    "        axes[0, 0].set_xlabel('Page Size')\n",
    "        axes[0, 0].set_ylabel('Records per Second')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[0, 0].text(0.5, 0.5, 'No pagination data', ha='center', va='center', transform=axes[0, 0].transAxes)\n",
    "else:\n",
    "    axes[0, 0].text(0.5, 0.5, 'No pagination data', ha='center', va='center', transform=axes[0, 0].transAxes)\n",
    "\n",
    "# Plot 2: Search Performance\n",
    "if 'search_df' in locals() and not search_df.empty:\n",
    "    successful_searches = search_df[search_df['success'] == True]\n",
    "    if not successful_searches.empty:\n",
    "        axes[0, 1].bar(range(len(successful_searches)), successful_searches['records_per_second'])\n",
    "        axes[0, 1].set_title('Search Operation Performance')\n",
    "        axes[0, 1].set_xlabel('Search Test')\n",
    "        axes[0, 1].set_ylabel('Records per Second')\n",
    "        axes[0, 1].set_xticks(range(len(successful_searches)))\n",
    "        axes[0, 1].set_xticklabels([f\"Test {i+1}\" for i in range(len(successful_searches))], rotation=45)\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[0, 1].text(0.5, 0.5, 'No search data', ha='center', va='center', transform=axes[0, 1].transAxes)\n",
    "else:\n",
    "    axes[0, 1].text(0.5, 0.5, 'No search data', ha='center', va='center', transform=axes[0, 1].transAxes)\n",
    "\n",
    "# Plot 3: Memory Usage\n",
    "if 'memory_df' in locals() and not memory_df.empty:\n",
    "    successful_memory = memory_df[memory_df['success'] == True]\n",
    "    if not successful_memory.empty:\n",
    "        axes[1, 0].plot(successful_memory['batch_size'], successful_memory['memory_per_record_kb'], 'o-')\n",
    "        axes[1, 0].set_title('Memory Efficiency')\n",
    "        axes[1, 0].set_xlabel('Batch Size')\n",
    "        axes[1, 0].set_ylabel('Memory per Record (KB)')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1, 0].text(0.5, 0.5, 'No memory data', ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "else:\n",
    "    axes[1, 0].text(0.5, 0.5, 'No memory data', ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "\n",
    "# Plot 4: Overall Performance Timeline\n",
    "perf_summary = perf_monitor.get_summary()\n",
    "if not perf_summary.empty:\n",
    "    successful_ops = perf_summary[perf_summary['success'] == True]\n",
    "    if not successful_ops.empty:\n",
    "        axes[1, 1].scatter(range(len(successful_ops)), successful_ops['duration'], alpha=0.7)\n",
    "        axes[1, 1].set_title('Operation Duration Timeline')\n",
    "        axes[1, 1].set_xlabel('Operation Sequence')\n",
    "        axes[1, 1].set_ylabel('Duration (seconds)')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add trend line\n",
    "        z = np.polyfit(range(len(successful_ops)), successful_ops['duration'], 1)\n",
    "        p = np.poly1d(z)\n",
    "        axes[1, 1].plot(range(len(successful_ops)), p(range(len(successful_ops))), \"r--\", alpha=0.8)\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'No timing data', ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, 'No timing data', ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Performance visualizations created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 8. Performance Recommendations\n",
    "\n",
    "Generate performance optimization recommendations based on test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T19:09:38.815859Z",
     "iopub.status.busy": "2025-10-03T19:09:38.815783Z",
     "iopub.status.idle": "2025-10-03T19:09:38.823646Z",
     "shell.execute_reply": "2025-10-03T19:09:38.823420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Generating performance optimization recommendations...\n",
      "\n",
      "üìä Overall Performance Summary:\n",
      "Total Operations: 16\n",
      "Successful Operations: 16\n",
      "Success Rate: 100.0%\n",
      "Average Duration: 31.01s\n",
      "Operations per Second: 0.03\n",
      "\n",
      "üéØ Performance Optimization Recommendations:\n",
      "============================================================\n",
      "\n",
      "üî¥ HIGH PRIORITY:\n",
      "  1. [Concurrency] Concurrent operations provide 38124.89x speedup. Use ThreadPoolExecutor for independent operations.\n",
      "     Impact: High\n",
      "\n",
      "üî¥ MEDIUM PRIORITY:\n",
      "  1. [Performance] Average operation time is 31.01s. Consider optimizing query complexity or using concurrent operations.\n",
      "     Impact: Medium\n",
      "  2. [Pagination] Use page size of 200 for optimal throughput (627.9 records/second).\n",
      "     Impact: Medium\n",
      "  3. [Best Practices] Implement exponential backoff for retry logic to handle temporary failures gracefully.\n",
      "     Impact: Medium\n",
      "  4. [Best Practices] Use field validation (validate=False) for known good requests to improve performance.\n",
      "     Impact: Low\n",
      "\n",
      "üî¥ LOW PRIORITY:\n",
      "  1. [Memory] For memory efficiency, use batch size of 500 (0.9 KB per record).\n",
      "     Impact: Low\n",
      "  2. [Best Practices] Monitor API rate limits and implement appropriate throttling to avoid hitting limits.\n",
      "     Impact: Medium\n",
      "\n",
      "üìä Recommendations Summary:\n",
      "priority  category      \n",
      "High      Concurrency       1\n",
      "Low       Best Practices    1\n",
      "          Memory            1\n",
      "Medium    Best Practices    2\n",
      "          Pagination        1\n",
      "          Performance       1\n"
     ]
    }
   ],
   "source": [
    "# Generate performance recommendations\n",
    "print(\"üéØ Generating performance optimization recommendations...\")\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "# Analyze overall performance\n",
    "overall_analysis = perf_monitor.analyze_performance()\n",
    "\n",
    "if overall_analysis:\n",
    "    print(f\"\\nüìä Overall Performance Summary:\")\n",
    "    print(f\"Total Operations: {overall_analysis.get('total_operations', 0)}\")\n",
    "    print(f\"Successful Operations: {overall_analysis.get('successful_operations', 0)}\")\n",
    "    print(f\"Success Rate: {overall_analysis.get('success_rate', 0):.1f}%\")\n",
    "    print(f\"Average Duration: {overall_analysis.get('avg_duration', 0):.2f}s\")\n",
    "    print(f\"Operations per Second: {overall_analysis.get('operations_per_second', 0):.2f}\")\n",
    "    \n",
    "    # Success rate recommendations\n",
    "    success_rate = overall_analysis.get('success_rate', 0)\n",
    "    if success_rate < 95:\n",
    "        recommendations.append({\n",
    "            'category': 'Reliability',\n",
    "            'priority': 'High',\n",
    "            'recommendation': f'Success rate is {success_rate:.1f}%. Implement retry logic and better error handling.',\n",
    "            'impact': 'High'\n",
    "        })\n",
    "    \n",
    "    # Performance recommendations\n",
    "    avg_duration = overall_analysis.get('avg_duration', 0)\n",
    "    if avg_duration > 2.0:\n",
    "        recommendations.append({\n",
    "            'category': 'Performance',\n",
    "            'priority': 'Medium',\n",
    "            'recommendation': f'Average operation time is {avg_duration:.2f}s. Consider optimizing query complexity or using concurrent operations.',\n",
    "            'impact': 'Medium'\n",
    "        })\n",
    "\n",
    "# Pagination recommendations\n",
    "if 'pagination_df' in locals() and not pagination_df.empty:\n",
    "    successful_pagination = pagination_df[pagination_df['success'] == True]\n",
    "    if not successful_pagination.empty:\n",
    "        optimal_page_size = successful_pagination.loc[successful_pagination['records_per_second'].idxmax()]\n",
    "        recommendations.append({\n",
    "            'category': 'Pagination',\n",
    "            'priority': 'Medium',\n",
    "            'recommendation': f'Use page size of {optimal_page_size[\"page_size\"]} for optimal throughput ({optimal_page_size[\"records_per_second\"]:.1f} records/second).',\n",
    "            'impact': 'Medium'\n",
    "        })\n",
    "\n",
    "# Memory usage recommendations\n",
    "if 'memory_df' in locals() and not memory_df.empty:\n",
    "    successful_memory = memory_df[memory_df['success'] == True]\n",
    "    if not successful_memory.empty and successful_memory['memory_per_record_kb'].sum() > 0:\n",
    "        avg_memory_per_record = successful_memory['memory_per_record_kb'].mean()\n",
    "        if avg_memory_per_record > 10:  # Threshold: 10KB per record\n",
    "            recommendations.append({\n",
    "                'category': 'Memory',\n",
    "                'priority': 'Low',\n",
    "                'recommendation': f'Memory usage is {avg_memory_per_record:.1f} KB per record. Consider processing in smaller batches to reduce memory footprint.',\n",
    "                'impact': 'Low'\n",
    "            })\n",
    "        \n",
    "        most_efficient = successful_memory.loc[successful_memory['memory_per_record_kb'].idxmin()]\n",
    "        recommendations.append({\n",
    "            'category': 'Memory',\n",
    "            'priority': 'Low',\n",
    "            'recommendation': f'For memory efficiency, use batch size of {most_efficient[\"batch_size\"]} ({most_efficient[\"memory_per_record_kb\"]:.1f} KB per record).',\n",
    "            'impact': 'Low'\n",
    "        })\n",
    "\n",
    "# Concurrency recommendations\n",
    "if 'sequential_total_time' in locals() and 'concurrent_total_time' in locals():\n",
    "    if concurrent_total_time < sequential_total_time:\n",
    "        speedup = sequential_total_time / concurrent_total_time\n",
    "        recommendations.append({\n",
    "            'category': 'Concurrency',\n",
    "            'priority': 'High',\n",
    "            'recommendation': f'Concurrent operations provide {speedup:.2f}x speedup. Use ThreadPoolExecutor for independent operations.',\n",
    "            'impact': 'High'\n",
    "        })\n",
    "    else:\n",
    "        recommendations.append({\n",
    "            'category': 'Concurrency',\n",
    "            'priority': 'Low',\n",
    "            'recommendation': 'Sequential operations performed better in this test. API may have rate limiting or connection constraints.',\n",
    "            'impact': 'Low'\n",
    "        })\n",
    "\n",
    "# General best practices\n",
    "recommendations.extend([\n",
    "    {\n",
    "        'category': 'Best Practices',\n",
    "        'priority': 'Medium',\n",
    "        'recommendation': 'Implement exponential backoff for retry logic to handle temporary failures gracefully.',\n",
    "        'impact': 'Medium'\n",
    "    },\n",
    "    {\n",
    "        'category': 'Best Practices',\n",
    "        'priority': 'Medium',\n",
    "        'recommendation': 'Use field validation (validate=False) for known good requests to improve performance.',\n",
    "        'impact': 'Low'\n",
    "    },\n",
    "    {\n",
    "        'category': 'Best Practices',\n",
    "        'priority': 'Low',\n",
    "        'recommendation': 'Monitor API rate limits and implement appropriate throttling to avoid hitting limits.',\n",
    "        'impact': 'Medium'\n",
    "    }\n",
    "])\n",
    "\n",
    "# Display recommendations\n",
    "if recommendations:\n",
    "    print(\"\\nüéØ Performance Optimization Recommendations:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Group by priority\n",
    "    high_priority = [r for r in recommendations if r['priority'] == 'High']\n",
    "    medium_priority = [r for r in recommendations if r['priority'] == 'Medium']\n",
    "    low_priority = [r for r in recommendations if r['priority'] == 'Low']\n",
    "    \n",
    "    for priority_group, label in [(high_priority, 'HIGH PRIORITY'), (medium_priority, 'MEDIUM PRIORITY'), (low_priority, 'LOW PRIORITY')]:\n",
    "        if priority_group:\n",
    "            print(f\"\\nüî¥ {label}:\")\n",
    "            for i, rec in enumerate(priority_group, 1):\n",
    "                print(f\"  {i}. [{rec['category']}] {rec['recommendation']}\")\n",
    "                print(f\"     Impact: {rec['impact']}\")\n",
    "    \n",
    "    # Create recommendations DataFrame\n",
    "    rec_df = pd.DataFrame(recommendations)\n",
    "    print(\"\\nüìä Recommendations Summary:\")\n",
    "    print(rec_df.groupby(['priority', 'category']).size().to_string())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No specific recommendations generated - insufficient performance data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides comprehensive batch operations performance analysis for the Neon CRM SDK:\n",
    "\n",
    "### ‚úÖ Performance Areas Analyzed:\n",
    "- **Single vs Batch Operations**: Comparing individual requests to batch operations\n",
    "- **Pagination Strategies**: Testing different page sizes for optimal throughput\n",
    "- **Search Performance**: Analyzing search operation efficiency\n",
    "- **Concurrent Operations**: Measuring benefits of parallel processing\n",
    "- **Memory Usage**: Monitoring memory consumption patterns\n",
    "- **Performance Visualization**: Creating charts for performance metrics\n",
    "\n",
    "### üéØ Key Performance Insights:\n",
    "- **Optimal Batch Sizes**: Identified through throughput analysis\n",
    "- **Memory Efficiency**: KB per record measurements across batch sizes\n",
    "- **Concurrency Benefits**: Speedup measurements for parallel operations\n",
    "- **Success Rate Analysis**: Reliability metrics for different operation types\n",
    "\n",
    "### üîß Performance Optimization Techniques:\n",
    "- **Smart Pagination**: Using optimal page sizes for maximum throughput\n",
    "- **Concurrent Processing**: ThreadPoolExecutor for independent operations\n",
    "- **Memory Management**: Garbage collection and batch size optimization\n",
    "- **Error Handling**: Comprehensive exception handling and retry logic\n",
    "\n",
    "### üìä Monitoring and Analysis:\n",
    "- **Real-time Performance Tracking**: PerformanceMonitor class for operation timing\n",
    "- **Memory Usage Monitoring**: psutil integration for memory analysis\n",
    "- **Visual Performance Analysis**: matplotlib/seaborn charts for trends\n",
    "- **Automated Recommendations**: Data-driven optimization suggestions\n",
    "\n",
    "### üöÄ Production Recommendations:\n",
    "- **Use Concurrent Operations**: For independent API calls when possible\n",
    "- **Implement Retry Logic**: With exponential backoff for reliability\n",
    "- **Monitor Rate Limits**: Implement throttling to avoid API limits\n",
    "- **Optimize Batch Sizes**: Use performance testing to find optimal sizes\n",
    "- **Memory Management**: Process large datasets in chunks to manage memory\n",
    "\n",
    "This analysis provides the foundation for building high-performance, scalable applications with the Neon CRM SDK."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
